{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Currency_GHonem.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "m2pxyDRkMRfN"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2pxyDRkMRfN"
      },
      "source": [
        "## mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5fbKQ8iMSCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b016dc-01f5-400a-c4e1-eaf4e4937f57"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8JeSQlln31b"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import tensorflow as tf\n",
        "#import tensorflow_hub as hub\n",
        "import math\n",
        "import itertools\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import shutil\n",
        "from keras.regularizers import l2\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YyBdGtU8fme"
      },
      "source": [
        "## unzib currency data partions and comine them into training and validition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1YQpH8P9Euv"
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "\n",
        "# Create a ZipFile Object and load sample.zip in it\\\n",
        "from zipfile import ZipFile \n",
        "with ZipFile('/content/drive/My Drive/Currency_Data/Valid_NewX.zip', 'r') as zipObj:\n",
        "# Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0DcSuS88kOQ"
      },
      "source": [
        "# Create a ZipFile Object and load sample.zip in it\\\n",
        "from zipfile import ZipFile \n",
        "with ZipFile('/content/drive/My Drive/Currency_Data/Curr_DataْX_5', 'r') as zipObj:\n",
        "# Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33YzzWrTDbYd"
      },
      "source": [
        "  \n",
        "os.mkdir('/content/10')\n",
        "\n",
        "os.chdir(\"/content/10\")\n",
        "# Create a ZipFile Object and load sample.zip in it\\\n",
        "from zipfile import ZipFile \n",
        "with ZipFile('/content/drive/My Drive/Currency_Data/Curr_DataْX_10.zip', 'r') as zipObj:\n",
        "# Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAmBUQqiDcvw"
      },
      "source": [
        "os.mkdir('/content/20')\n",
        "\n",
        "os.chdir(\"/content/20\")\n",
        "# Create a ZipFile Object and load sample.zip in it\\\n",
        "from zipfile import ZipFile \n",
        "with ZipFile('/content/drive/My Drive/Currency_Data/Curr_DataْX_20.zip', 'r') as zipObj:\n",
        "# Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__CHUeWBDcs_"
      },
      "source": [
        "os.mkdir('/content/50')\n",
        "\n",
        "os.chdir(\"/content/50\")\n",
        "# Create a ZipFile Object and load sample.zip in it\\\n",
        "from zipfile import ZipFile \n",
        "with ZipFile('/content/drive/My Drive/Currency_Data/Curr_DataْX_50.zip', 'r') as zipObj:\n",
        "# Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlJK5GBSDcqg"
      },
      "source": [
        "os.mkdir('/content/100')\n",
        "\n",
        "os.chdir(\"/content/100\")\n",
        "# Create a ZipFile Object and load sample.zip in it\\\n",
        "from zipfile import ZipFile \n",
        "with ZipFile('/content/drive/My Drive/Currency_Data/Curr_DataْX_100.zip', 'r') as zipObj:\n",
        "# Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tRH-liSDcns"
      },
      "source": [
        "os.mkdir('/content/200')\n",
        "\n",
        "os.chdir(\"/content/200\")\n",
        "# Create a ZipFile Object and load sample.zip in it\\\n",
        "from zipfile import ZipFile \n",
        "with ZipFile('/content/drive/My Drive/Currency_Data/Curr_DataْX_200.zip', 'r') as zipObj:\n",
        "# Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYwsdQQbMcpL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "415caf4c-15e5-4fe8-b69b-e8052c2cbe90"
      },
      "source": [
        "os.mkdir('/content/EG_curr_data/')\n",
        "os.mkdir('/content/EG_curr_data/train')\n",
        "\n",
        "\n",
        "shutil.move('/content/content/Data/5B', '/content/EG_curr_data/train')\n",
        "shutil.move('/content/content/Data/5F', '/content/EG_curr_data/train')\n",
        "\n",
        "shutil.move('/content/10/content/Data/10B', '/content/EG_curr_data/train')\n",
        "shutil.move('/content/10/content/Data/10F', '/content/EG_curr_data/train')\n",
        "\n",
        "shutil.move('/content/20/content/Data/20B', '/content/EG_curr_data/train')\n",
        "shutil.move('/content/20/content/Data/20F', '/content/EG_curr_data/train')\n",
        "\n",
        "shutil.move('/content/50/content/Data/50B', '/content/EG_curr_data/train')\n",
        "shutil.move('/content/50/content/Data/50F', '/content/EG_curr_data/train')\n",
        "\n",
        "shutil.move('/content/100/content/Data/100B', '/content/EG_curr_data/train')\n",
        "shutil.move('/content/100/content/Data/100F', '/content/EG_curr_data/train')\n",
        "\n",
        "shutil.move('/content/200/content/Data/200B', '/content/EG_curr_data/train')\n",
        "shutil.move('/content/200/content/Data/200F', '/content/EG_curr_data/train')\n",
        "\n",
        "shutil.move(\"/content/content/drive/My Drive/Currency_data+new/valid\",\"/content/EG_curr_data/valid\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/EG_curr_data/valid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk2DWZZRMiQO"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXC-Wp4ObThF"
      },
      "source": [
        "base_dir = '/content/EG_curr_data'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'valid')\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 64\n",
        "IMG_SHAPE = 350 # Our training data will consists of images with width of 150 pixels and height of 150 pixels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT57gOQ5bzl1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "361257af-4b82-4e84-b634-84b52c87c509"
      },
      "source": [
        "pre_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet',input_shape=(350, 350, 3),classes=12)\n",
        "pre_model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_resnet_v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 350, 350, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1015 (Conv2D)            (None, 174, 174, 32) 864         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1015 (Batch (None, 174, 174, 32) 96          conv2d_1015[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1015 (Activation)    (None, 174, 174, 32) 0           batch_normalization_1015[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1016 (Conv2D)            (None, 172, 172, 32) 9216        activation_1015[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1016 (Batch (None, 172, 172, 32) 96          conv2d_1016[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1016 (Activation)    (None, 172, 172, 32) 0           batch_normalization_1016[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1017 (Conv2D)            (None, 172, 172, 64) 18432       activation_1016[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1017 (Batch (None, 172, 172, 64) 192         conv2d_1017[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1017 (Activation)    (None, 172, 172, 64) 0           batch_normalization_1017[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 85, 85, 64)   0           activation_1017[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1018 (Conv2D)            (None, 85, 85, 80)   5120        max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1018 (Batch (None, 85, 85, 80)   240         conv2d_1018[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1018 (Activation)    (None, 85, 85, 80)   0           batch_normalization_1018[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1019 (Conv2D)            (None, 83, 83, 192)  138240      activation_1018[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1019 (Batch (None, 83, 83, 192)  576         conv2d_1019[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1019 (Activation)    (None, 83, 83, 192)  0           batch_normalization_1019[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, 41, 41, 192)  0           activation_1019[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1023 (Conv2D)            (None, 41, 41, 64)   12288       max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1023 (Batch (None, 41, 41, 64)   192         conv2d_1023[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1023 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1023[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1021 (Conv2D)            (None, 41, 41, 48)   9216        max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1024 (Conv2D)            (None, 41, 41, 96)   55296       activation_1023[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1021 (Batch (None, 41, 41, 48)   144         conv2d_1021[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1024 (Batch (None, 41, 41, 96)   288         conv2d_1024[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1021 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1021[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1024 (Activation)    (None, 41, 41, 96)   0           batch_normalization_1024[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 41, 41, 192)  0           max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1020 (Conv2D)            (None, 41, 41, 96)   18432       max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1022 (Conv2D)            (None, 41, 41, 64)   76800       activation_1021[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1025 (Conv2D)            (None, 41, 41, 96)   82944       activation_1024[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1026 (Conv2D)            (None, 41, 41, 64)   12288       average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1020 (Batch (None, 41, 41, 96)   288         conv2d_1020[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1022 (Batch (None, 41, 41, 64)   192         conv2d_1022[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1025 (Batch (None, 41, 41, 96)   288         conv2d_1025[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1026 (Batch (None, 41, 41, 64)   192         conv2d_1026[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1020 (Activation)    (None, 41, 41, 96)   0           batch_normalization_1020[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1022 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1022[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1025 (Activation)    (None, 41, 41, 96)   0           batch_normalization_1025[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1026 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1026[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, 41, 41, 320)  0           activation_1020[0][0]            \n",
            "                                                                 activation_1022[0][0]            \n",
            "                                                                 activation_1025[0][0]            \n",
            "                                                                 activation_1026[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1030 (Conv2D)            (None, 41, 41, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1030 (Batch (None, 41, 41, 32)   96          conv2d_1030[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1030 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1030[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1028 (Conv2D)            (None, 41, 41, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1031 (Conv2D)            (None, 41, 41, 48)   13824       activation_1030[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1028 (Batch (None, 41, 41, 32)   96          conv2d_1028[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1031 (Batch (None, 41, 41, 48)   144         conv2d_1031[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1028 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1028[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1031 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1031[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1027 (Conv2D)            (None, 41, 41, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1029 (Conv2D)            (None, 41, 41, 32)   9216        activation_1028[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1032 (Conv2D)            (None, 41, 41, 64)   27648       activation_1031[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1027 (Batch (None, 41, 41, 32)   96          conv2d_1027[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1029 (Batch (None, 41, 41, 32)   96          conv2d_1029[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1032 (Batch (None, 41, 41, 64)   192         conv2d_1032[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1027 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1027[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1029 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1029[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1032 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1032[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1027[0][0]            \n",
            "                                                                 activation_1029[0][0]            \n",
            "                                                                 activation_1032[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, 41, 41, 320)  0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, 41, 41, 320)  0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1036 (Conv2D)            (None, 41, 41, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1036 (Batch (None, 41, 41, 32)   96          conv2d_1036[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1036 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1036[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1034 (Conv2D)            (None, 41, 41, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1037 (Conv2D)            (None, 41, 41, 48)   13824       activation_1036[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1034 (Batch (None, 41, 41, 32)   96          conv2d_1034[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1037 (Batch (None, 41, 41, 48)   144         conv2d_1037[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1034 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1034[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1037 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1037[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1033 (Conv2D)            (None, 41, 41, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1035 (Conv2D)            (None, 41, 41, 32)   9216        activation_1034[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1038 (Conv2D)            (None, 41, 41, 64)   27648       activation_1037[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1033 (Batch (None, 41, 41, 32)   96          conv2d_1033[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1035 (Batch (None, 41, 41, 32)   96          conv2d_1035[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1038 (Batch (None, 41, 41, 64)   192         conv2d_1038[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1033 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1033[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1035 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1035[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1038 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1038[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1033[0][0]            \n",
            "                                                                 activation_1035[0][0]            \n",
            "                                                                 activation_1038[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, 41, 41, 320)  0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, 41, 41, 320)  0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1042 (Conv2D)            (None, 41, 41, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1042 (Batch (None, 41, 41, 32)   96          conv2d_1042[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1042 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1042[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1040 (Conv2D)            (None, 41, 41, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1043 (Conv2D)            (None, 41, 41, 48)   13824       activation_1042[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1040 (Batch (None, 41, 41, 32)   96          conv2d_1040[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1043 (Batch (None, 41, 41, 48)   144         conv2d_1043[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1040 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1040[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1043 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1043[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1039 (Conv2D)            (None, 41, 41, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1041 (Conv2D)            (None, 41, 41, 32)   9216        activation_1040[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1044 (Conv2D)            (None, 41, 41, 64)   27648       activation_1043[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1039 (Batch (None, 41, 41, 32)   96          conv2d_1039[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1041 (Batch (None, 41, 41, 32)   96          conv2d_1041[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1044 (Batch (None, 41, 41, 64)   192         conv2d_1044[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1039 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1039[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1041 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1041[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1044 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1044[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1039[0][0]            \n",
            "                                                                 activation_1041[0][0]            \n",
            "                                                                 activation_1044[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, 41, 41, 320)  0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, 41, 41, 320)  0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1048 (Conv2D)            (None, 41, 41, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1048 (Batch (None, 41, 41, 32)   96          conv2d_1048[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1048 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1048[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1046 (Conv2D)            (None, 41, 41, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1049 (Conv2D)            (None, 41, 41, 48)   13824       activation_1048[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1046 (Batch (None, 41, 41, 32)   96          conv2d_1046[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1049 (Batch (None, 41, 41, 48)   144         conv2d_1049[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1046 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1046[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1049 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1049[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1045 (Conv2D)            (None, 41, 41, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1047 (Conv2D)            (None, 41, 41, 32)   9216        activation_1046[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1050 (Conv2D)            (None, 41, 41, 64)   27648       activation_1049[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1045 (Batch (None, 41, 41, 32)   96          conv2d_1045[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1047 (Batch (None, 41, 41, 32)   96          conv2d_1047[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1050 (Batch (None, 41, 41, 64)   192         conv2d_1050[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1045 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1045[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1047 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1047[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1050 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1050[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1045[0][0]            \n",
            "                                                                 activation_1047[0][0]            \n",
            "                                                                 activation_1050[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, 41, 41, 320)  0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, 41, 41, 320)  0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1054 (Conv2D)            (None, 41, 41, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1054 (Batch (None, 41, 41, 32)   96          conv2d_1054[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1054 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1054[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1052 (Conv2D)            (None, 41, 41, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1055 (Conv2D)            (None, 41, 41, 48)   13824       activation_1054[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1052 (Batch (None, 41, 41, 32)   96          conv2d_1052[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1055 (Batch (None, 41, 41, 48)   144         conv2d_1055[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1052 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1052[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1055 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1055[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1051 (Conv2D)            (None, 41, 41, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1053 (Conv2D)            (None, 41, 41, 32)   9216        activation_1052[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1056 (Conv2D)            (None, 41, 41, 64)   27648       activation_1055[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1051 (Batch (None, 41, 41, 32)   96          conv2d_1051[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1053 (Batch (None, 41, 41, 32)   96          conv2d_1053[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1056 (Batch (None, 41, 41, 64)   192         conv2d_1056[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1051 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1051[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1053 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1053[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1056 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1056[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1051[0][0]            \n",
            "                                                                 activation_1053[0][0]            \n",
            "                                                                 activation_1056[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, 41, 41, 320)  0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, 41, 41, 320)  0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1060 (Conv2D)            (None, 41, 41, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1060 (Batch (None, 41, 41, 32)   96          conv2d_1060[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1060 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1060[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1058 (Conv2D)            (None, 41, 41, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1061 (Conv2D)            (None, 41, 41, 48)   13824       activation_1060[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1058 (Batch (None, 41, 41, 32)   96          conv2d_1058[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1061 (Batch (None, 41, 41, 48)   144         conv2d_1061[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1058 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1058[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1061 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1061[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1057 (Conv2D)            (None, 41, 41, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1059 (Conv2D)            (None, 41, 41, 32)   9216        activation_1058[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1062 (Conv2D)            (None, 41, 41, 64)   27648       activation_1061[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1057 (Batch (None, 41, 41, 32)   96          conv2d_1057[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1059 (Batch (None, 41, 41, 32)   96          conv2d_1059[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1062 (Batch (None, 41, 41, 64)   192         conv2d_1062[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1057 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1057[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1059 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1059[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1062 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1062[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1057[0][0]            \n",
            "                                                                 activation_1059[0][0]            \n",
            "                                                                 activation_1062[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, 41, 41, 320)  0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, 41, 41, 320)  0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1066 (Conv2D)            (None, 41, 41, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1066 (Batch (None, 41, 41, 32)   96          conv2d_1066[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1066 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1066[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1064 (Conv2D)            (None, 41, 41, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1067 (Conv2D)            (None, 41, 41, 48)   13824       activation_1066[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1064 (Batch (None, 41, 41, 32)   96          conv2d_1064[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1067 (Batch (None, 41, 41, 48)   144         conv2d_1067[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1064 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1064[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1067 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1067[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1063 (Conv2D)            (None, 41, 41, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1065 (Conv2D)            (None, 41, 41, 32)   9216        activation_1064[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1068 (Conv2D)            (None, 41, 41, 64)   27648       activation_1067[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1063 (Batch (None, 41, 41, 32)   96          conv2d_1063[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1065 (Batch (None, 41, 41, 32)   96          conv2d_1065[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1068 (Batch (None, 41, 41, 64)   192         conv2d_1068[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1063 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1063[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1065 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1065[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1068 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1068[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1063[0][0]            \n",
            "                                                                 activation_1065[0][0]            \n",
            "                                                                 activation_1068[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, 41, 41, 320)  0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, 41, 41, 320)  0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1072 (Conv2D)            (None, 41, 41, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1072 (Batch (None, 41, 41, 32)   96          conv2d_1072[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1072 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1072[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1070 (Conv2D)            (None, 41, 41, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1073 (Conv2D)            (None, 41, 41, 48)   13824       activation_1072[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1070 (Batch (None, 41, 41, 32)   96          conv2d_1070[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1073 (Batch (None, 41, 41, 48)   144         conv2d_1073[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1070 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1070[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1073 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1073[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1069 (Conv2D)            (None, 41, 41, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1071 (Conv2D)            (None, 41, 41, 32)   9216        activation_1070[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1074 (Conv2D)            (None, 41, 41, 64)   27648       activation_1073[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1069 (Batch (None, 41, 41, 32)   96          conv2d_1069[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1071 (Batch (None, 41, 41, 32)   96          conv2d_1071[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1074 (Batch (None, 41, 41, 64)   192         conv2d_1074[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1069 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1069[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1071 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1071[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1074 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1074[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1069[0][0]            \n",
            "                                                                 activation_1071[0][0]            \n",
            "                                                                 activation_1074[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, 41, 41, 320)  0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, 41, 41, 320)  0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1078 (Conv2D)            (None, 41, 41, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1078 (Batch (None, 41, 41, 32)   96          conv2d_1078[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1078 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1078[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1076 (Conv2D)            (None, 41, 41, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1079 (Conv2D)            (None, 41, 41, 48)   13824       activation_1078[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1076 (Batch (None, 41, 41, 32)   96          conv2d_1076[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1079 (Batch (None, 41, 41, 48)   144         conv2d_1079[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1076 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1076[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1079 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1079[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1075 (Conv2D)            (None, 41, 41, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1077 (Conv2D)            (None, 41, 41, 32)   9216        activation_1076[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1080 (Conv2D)            (None, 41, 41, 64)   27648       activation_1079[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1075 (Batch (None, 41, 41, 32)   96          conv2d_1075[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1077 (Batch (None, 41, 41, 32)   96          conv2d_1077[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1080 (Batch (None, 41, 41, 64)   192         conv2d_1080[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1075 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1075[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1077 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1077[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1080 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1080[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, 41, 41, 128)  0           activation_1075[0][0]            \n",
            "                                                                 activation_1077[0][0]            \n",
            "                                                                 activation_1080[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, 41, 41, 320)  41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, 41, 41, 320)  0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, 41, 41, 320)  0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1084 (Conv2D)            (None, 41, 41, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1084 (Batch (None, 41, 41, 32)   96          conv2d_1084[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1084 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1084[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1082 (Conv2D)            (None, 41, 41, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1085 (Conv2D)            (None, 41, 41, 48)   13824       activation_1084[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1082 (Batch (None, 41, 41, 32)   96          conv2d_1082[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1085 (Batch (None, 41, 41, 48)   144         conv2d_1085[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1082 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1082[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1085 (Activation)    (None, 41, 41, 48)   0           batch_normalization_1085[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1081 (Conv2D)            (None, 41, 41, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1083 (Conv2D)            (None, 41, 41, 32)   9216        activation_1082[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1086 (Conv2D)            (None, 41, 41, 64)   27648       activation_1085[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1081 (Batch (None, 41, 41, 32)   96          conv2d_1081[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1083 (Batch (None, 41, 41, 32)   96          conv2d_1083[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1086 (Batch (None, 41, 41, 64)   192         conv2d_1086[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1081 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1081[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1083 (Activation)    (None, 41, 41, 32)   0           batch_normalization_1083[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1086 (Activation)    (None, 41, 41, 64)   0           batch_normalization_1086[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, 41, 41, 128)  0           activation_1081[0][0]            \n",
            "                                                                 activation_1083[0][0]            \n",
            "                                                                 activation_1086[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, 41, 41, 320)  41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, 41, 41, 320)  0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, 41, 41, 320)  0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1088 (Conv2D)            (None, 41, 41, 256)  81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1088 (Batch (None, 41, 41, 256)  768         conv2d_1088[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1088 (Activation)    (None, 41, 41, 256)  0           batch_normalization_1088[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1089 (Conv2D)            (None, 41, 41, 256)  589824      activation_1088[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1089 (Batch (None, 41, 41, 256)  768         conv2d_1089[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1089 (Activation)    (None, 41, 41, 256)  0           batch_normalization_1089[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1087 (Conv2D)            (None, 20, 20, 384)  1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1090 (Conv2D)            (None, 20, 20, 384)  884736      activation_1089[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1087 (Batch (None, 20, 20, 384)  1152        conv2d_1087[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1090 (Batch (None, 20, 20, 384)  1152        conv2d_1090[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1087 (Activation)    (None, 20, 20, 384)  0           batch_normalization_1087[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1090 (Activation)    (None, 20, 20, 384)  0           batch_normalization_1090[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, 20, 20, 320)  0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, 20, 20, 1088) 0           activation_1087[0][0]            \n",
            "                                                                 activation_1090[0][0]            \n",
            "                                                                 max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1092 (Conv2D)            (None, 20, 20, 128)  139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1092 (Batch (None, 20, 20, 128)  384         conv2d_1092[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1092 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1092[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1093 (Conv2D)            (None, 20, 20, 160)  143360      activation_1092[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1093 (Batch (None, 20, 20, 160)  480         conv2d_1093[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1093 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1093[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1091 (Conv2D)            (None, 20, 20, 192)  208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1094 (Conv2D)            (None, 20, 20, 192)  215040      activation_1093[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1091 (Batch (None, 20, 20, 192)  576         conv2d_1091[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1094 (Batch (None, 20, 20, 192)  576         conv2d_1094[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1091 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1091[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1094 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1094[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1091[0][0]            \n",
            "                                                                 activation_1094[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, 20, 20, 1088) 0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, 20, 20, 1088) 0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1096 (Conv2D)            (None, 20, 20, 128)  139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1096 (Batch (None, 20, 20, 128)  384         conv2d_1096[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1096 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1096[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1097 (Conv2D)            (None, 20, 20, 160)  143360      activation_1096[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1097 (Batch (None, 20, 20, 160)  480         conv2d_1097[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1097 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1097[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1095 (Conv2D)            (None, 20, 20, 192)  208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1098 (Conv2D)            (None, 20, 20, 192)  215040      activation_1097[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1095 (Batch (None, 20, 20, 192)  576         conv2d_1095[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1098 (Batch (None, 20, 20, 192)  576         conv2d_1098[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1095 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1095[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1098 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1098[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1095[0][0]            \n",
            "                                                                 activation_1098[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, 20, 20, 1088) 0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, 20, 20, 1088) 0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1100 (Conv2D)            (None, 20, 20, 128)  139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1100 (Batch (None, 20, 20, 128)  384         conv2d_1100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1100 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1100[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1101 (Conv2D)            (None, 20, 20, 160)  143360      activation_1100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1101 (Batch (None, 20, 20, 160)  480         conv2d_1101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1101 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1101[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1099 (Conv2D)            (None, 20, 20, 192)  208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1102 (Conv2D)            (None, 20, 20, 192)  215040      activation_1101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1099 (Batch (None, 20, 20, 192)  576         conv2d_1099[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1102 (Batch (None, 20, 20, 192)  576         conv2d_1102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1099 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1099[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1102 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1102[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1099[0][0]            \n",
            "                                                                 activation_1102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, 20, 20, 1088) 0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, 20, 20, 1088) 0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1104 (Conv2D)            (None, 20, 20, 128)  139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1104 (Batch (None, 20, 20, 128)  384         conv2d_1104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1104 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1104[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1105 (Conv2D)            (None, 20, 20, 160)  143360      activation_1104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1105 (Batch (None, 20, 20, 160)  480         conv2d_1105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1105 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1105[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1103 (Conv2D)            (None, 20, 20, 192)  208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1106 (Conv2D)            (None, 20, 20, 192)  215040      activation_1105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1103 (Batch (None, 20, 20, 192)  576         conv2d_1103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1106 (Batch (None, 20, 20, 192)  576         conv2d_1106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1103 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1103[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1106 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1106[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1103[0][0]            \n",
            "                                                                 activation_1106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, 20, 20, 1088) 0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, 20, 20, 1088) 0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1108 (Conv2D)            (None, 20, 20, 128)  139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1108 (Batch (None, 20, 20, 128)  384         conv2d_1108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1108 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1108[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1109 (Conv2D)            (None, 20, 20, 160)  143360      activation_1108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1109 (Batch (None, 20, 20, 160)  480         conv2d_1109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1109 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1109[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1107 (Conv2D)            (None, 20, 20, 192)  208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1110 (Conv2D)            (None, 20, 20, 192)  215040      activation_1109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1107 (Batch (None, 20, 20, 192)  576         conv2d_1107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1110 (Batch (None, 20, 20, 192)  576         conv2d_1110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1107 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1107[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1110 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1110[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1107[0][0]            \n",
            "                                                                 activation_1110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, 20, 20, 1088) 0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, 20, 20, 1088) 0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1112 (Conv2D)            (None, 20, 20, 128)  139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1112 (Batch (None, 20, 20, 128)  384         conv2d_1112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1112 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1112[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1113 (Conv2D)            (None, 20, 20, 160)  143360      activation_1112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1113 (Batch (None, 20, 20, 160)  480         conv2d_1113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1113 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1113[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1111 (Conv2D)            (None, 20, 20, 192)  208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1114 (Conv2D)            (None, 20, 20, 192)  215040      activation_1113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1111 (Batch (None, 20, 20, 192)  576         conv2d_1111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1114 (Batch (None, 20, 20, 192)  576         conv2d_1114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1111 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1111[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1114 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1114[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1111[0][0]            \n",
            "                                                                 activation_1114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, 20, 20, 1088) 0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, 20, 20, 1088) 0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1116 (Conv2D)            (None, 20, 20, 128)  139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1116 (Batch (None, 20, 20, 128)  384         conv2d_1116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1116 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1116[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1117 (Conv2D)            (None, 20, 20, 160)  143360      activation_1116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1117 (Batch (None, 20, 20, 160)  480         conv2d_1117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1117 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1117[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1115 (Conv2D)            (None, 20, 20, 192)  208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1118 (Conv2D)            (None, 20, 20, 192)  215040      activation_1117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1115 (Batch (None, 20, 20, 192)  576         conv2d_1115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1118 (Batch (None, 20, 20, 192)  576         conv2d_1118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1115 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1115[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1118 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1118[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1115[0][0]            \n",
            "                                                                 activation_1118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, 20, 20, 1088) 0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, 20, 20, 1088) 0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1120 (Conv2D)            (None, 20, 20, 128)  139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1120 (Batch (None, 20, 20, 128)  384         conv2d_1120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1120 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1120[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1121 (Conv2D)            (None, 20, 20, 160)  143360      activation_1120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1121 (Batch (None, 20, 20, 160)  480         conv2d_1121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1121 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1121[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1119 (Conv2D)            (None, 20, 20, 192)  208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1122 (Conv2D)            (None, 20, 20, 192)  215040      activation_1121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1119 (Batch (None, 20, 20, 192)  576         conv2d_1119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1122 (Batch (None, 20, 20, 192)  576         conv2d_1122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1119 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1119[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1122 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1122[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1119[0][0]            \n",
            "                                                                 activation_1122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, 20, 20, 1088) 0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, 20, 20, 1088) 0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1124 (Conv2D)            (None, 20, 20, 128)  139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1124 (Batch (None, 20, 20, 128)  384         conv2d_1124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1124 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1124[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1125 (Conv2D)            (None, 20, 20, 160)  143360      activation_1124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1125 (Batch (None, 20, 20, 160)  480         conv2d_1125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1125 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1125[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1123 (Conv2D)            (None, 20, 20, 192)  208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1126 (Conv2D)            (None, 20, 20, 192)  215040      activation_1125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1123 (Batch (None, 20, 20, 192)  576         conv2d_1123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1126 (Batch (None, 20, 20, 192)  576         conv2d_1126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1123 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1123[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1126 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1126[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, 20, 20, 384)  0           activation_1123[0][0]            \n",
            "                                                                 activation_1126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, 20, 20, 1088) 418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, 20, 20, 1088) 0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, 20, 20, 1088) 0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1128 (Conv2D)            (None, 20, 20, 128)  139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1128 (Batch (None, 20, 20, 128)  384         conv2d_1128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1128 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1128[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1129 (Conv2D)            (None, 20, 20, 160)  143360      activation_1128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1129 (Batch (None, 20, 20, 160)  480         conv2d_1129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1129 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1129[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1127 (Conv2D)            (None, 20, 20, 192)  208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1130 (Conv2D)            (None, 20, 20, 192)  215040      activation_1129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1127 (Batch (None, 20, 20, 192)  576         conv2d_1127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1130 (Batch (None, 20, 20, 192)  576         conv2d_1130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1127 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1127[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1130 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1130[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1127[0][0]            \n",
            "                                                                 activation_1130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, 20, 20, 1088) 0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, 20, 20, 1088) 0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1132 (Conv2D)            (None, 20, 20, 128)  139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1132 (Batch (None, 20, 20, 128)  384         conv2d_1132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1132 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1132[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1133 (Conv2D)            (None, 20, 20, 160)  143360      activation_1132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1133 (Batch (None, 20, 20, 160)  480         conv2d_1133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1133 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1133[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1131 (Conv2D)            (None, 20, 20, 192)  208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1134 (Conv2D)            (None, 20, 20, 192)  215040      activation_1133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1131 (Batch (None, 20, 20, 192)  576         conv2d_1131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1134 (Batch (None, 20, 20, 192)  576         conv2d_1134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1131 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1131[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1134 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1134[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1131[0][0]            \n",
            "                                                                 activation_1134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, 20, 20, 1088) 0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, 20, 20, 1088) 0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1136 (Conv2D)            (None, 20, 20, 128)  139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1136 (Batch (None, 20, 20, 128)  384         conv2d_1136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1136 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1136[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1137 (Conv2D)            (None, 20, 20, 160)  143360      activation_1136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1137 (Batch (None, 20, 20, 160)  480         conv2d_1137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1137 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1137[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1135 (Conv2D)            (None, 20, 20, 192)  208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1138 (Conv2D)            (None, 20, 20, 192)  215040      activation_1137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1135 (Batch (None, 20, 20, 192)  576         conv2d_1135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1138 (Batch (None, 20, 20, 192)  576         conv2d_1138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1135 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1135[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1138 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1138[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1135[0][0]            \n",
            "                                                                 activation_1138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, 20, 20, 1088) 0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, 20, 20, 1088) 0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1140 (Conv2D)            (None, 20, 20, 128)  139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1140 (Batch (None, 20, 20, 128)  384         conv2d_1140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1140 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1140[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1141 (Conv2D)            (None, 20, 20, 160)  143360      activation_1140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1141 (Batch (None, 20, 20, 160)  480         conv2d_1141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1141 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1141[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1139 (Conv2D)            (None, 20, 20, 192)  208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1142 (Conv2D)            (None, 20, 20, 192)  215040      activation_1141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1139 (Batch (None, 20, 20, 192)  576         conv2d_1139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1142 (Batch (None, 20, 20, 192)  576         conv2d_1142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1139 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1139[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1142 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1142[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1139[0][0]            \n",
            "                                                                 activation_1142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, 20, 20, 1088) 0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, 20, 20, 1088) 0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1144 (Conv2D)            (None, 20, 20, 128)  139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1144 (Batch (None, 20, 20, 128)  384         conv2d_1144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1144 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1144[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1145 (Conv2D)            (None, 20, 20, 160)  143360      activation_1144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1145 (Batch (None, 20, 20, 160)  480         conv2d_1145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1145 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1145[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1143 (Conv2D)            (None, 20, 20, 192)  208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1146 (Conv2D)            (None, 20, 20, 192)  215040      activation_1145[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1143 (Batch (None, 20, 20, 192)  576         conv2d_1143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1146 (Batch (None, 20, 20, 192)  576         conv2d_1146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1143 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1143[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1146 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1146[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1143[0][0]            \n",
            "                                                                 activation_1146[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, 20, 20, 1088) 0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, 20, 20, 1088) 0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1148 (Conv2D)            (None, 20, 20, 128)  139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1148 (Batch (None, 20, 20, 128)  384         conv2d_1148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1148 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1148[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1149 (Conv2D)            (None, 20, 20, 160)  143360      activation_1148[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1149 (Batch (None, 20, 20, 160)  480         conv2d_1149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1149 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1149[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1147 (Conv2D)            (None, 20, 20, 192)  208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1150 (Conv2D)            (None, 20, 20, 192)  215040      activation_1149[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1147 (Batch (None, 20, 20, 192)  576         conv2d_1147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1150 (Batch (None, 20, 20, 192)  576         conv2d_1150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1147 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1147[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1150 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1150[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1147[0][0]            \n",
            "                                                                 activation_1150[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, 20, 20, 1088) 0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, 20, 20, 1088) 0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1152 (Conv2D)            (None, 20, 20, 128)  139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1152 (Batch (None, 20, 20, 128)  384         conv2d_1152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1152 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1152[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1153 (Conv2D)            (None, 20, 20, 160)  143360      activation_1152[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1153 (Batch (None, 20, 20, 160)  480         conv2d_1153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1153 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1153[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1151 (Conv2D)            (None, 20, 20, 192)  208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1154 (Conv2D)            (None, 20, 20, 192)  215040      activation_1153[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1151 (Batch (None, 20, 20, 192)  576         conv2d_1151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1154 (Batch (None, 20, 20, 192)  576         conv2d_1154[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1151 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1151[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1154 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1154[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1151[0][0]            \n",
            "                                                                 activation_1154[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, 20, 20, 1088) 0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, 20, 20, 1088) 0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1156 (Conv2D)            (None, 20, 20, 128)  139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1156 (Batch (None, 20, 20, 128)  384         conv2d_1156[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1156 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1156[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1157 (Conv2D)            (None, 20, 20, 160)  143360      activation_1156[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1157 (Batch (None, 20, 20, 160)  480         conv2d_1157[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1157 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1157[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1155 (Conv2D)            (None, 20, 20, 192)  208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1158 (Conv2D)            (None, 20, 20, 192)  215040      activation_1157[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1155 (Batch (None, 20, 20, 192)  576         conv2d_1155[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1158 (Batch (None, 20, 20, 192)  576         conv2d_1158[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1155 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1155[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1158 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1158[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1155[0][0]            \n",
            "                                                                 activation_1158[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, 20, 20, 1088) 0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, 20, 20, 1088) 0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1160 (Conv2D)            (None, 20, 20, 128)  139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1160 (Batch (None, 20, 20, 128)  384         conv2d_1160[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1160 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1160[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1161 (Conv2D)            (None, 20, 20, 160)  143360      activation_1160[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1161 (Batch (None, 20, 20, 160)  480         conv2d_1161[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1161 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1161[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1159 (Conv2D)            (None, 20, 20, 192)  208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1162 (Conv2D)            (None, 20, 20, 192)  215040      activation_1161[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1159 (Batch (None, 20, 20, 192)  576         conv2d_1159[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1162 (Batch (None, 20, 20, 192)  576         conv2d_1162[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1159 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1159[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1162 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1162[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1159[0][0]            \n",
            "                                                                 activation_1162[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, 20, 20, 1088) 0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, 20, 20, 1088) 0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1164 (Conv2D)            (None, 20, 20, 128)  139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1164 (Batch (None, 20, 20, 128)  384         conv2d_1164[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1164 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1164[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1165 (Conv2D)            (None, 20, 20, 160)  143360      activation_1164[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1165 (Batch (None, 20, 20, 160)  480         conv2d_1165[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1165 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1165[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1163 (Conv2D)            (None, 20, 20, 192)  208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1166 (Conv2D)            (None, 20, 20, 192)  215040      activation_1165[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1163 (Batch (None, 20, 20, 192)  576         conv2d_1163[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1166 (Batch (None, 20, 20, 192)  576         conv2d_1166[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1163 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1163[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1166 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1166[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1163[0][0]            \n",
            "                                                                 activation_1166[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, 20, 20, 1088) 0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, 20, 20, 1088) 0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1168 (Conv2D)            (None, 20, 20, 128)  139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1168 (Batch (None, 20, 20, 128)  384         conv2d_1168[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1168 (Activation)    (None, 20, 20, 128)  0           batch_normalization_1168[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1169 (Conv2D)            (None, 20, 20, 160)  143360      activation_1168[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1169 (Batch (None, 20, 20, 160)  480         conv2d_1169[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1169 (Activation)    (None, 20, 20, 160)  0           batch_normalization_1169[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1167 (Conv2D)            (None, 20, 20, 192)  208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1170 (Conv2D)            (None, 20, 20, 192)  215040      activation_1169[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1167 (Batch (None, 20, 20, 192)  576         conv2d_1167[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1170 (Batch (None, 20, 20, 192)  576         conv2d_1170[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1167 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1167[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1170 (Activation)    (None, 20, 20, 192)  0           batch_normalization_1170[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, 20, 20, 384)  0           activation_1167[0][0]            \n",
            "                                                                 activation_1170[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, 20, 20, 1088) 418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, 20, 20, 1088) 0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, 20, 20, 1088) 0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1175 (Conv2D)            (None, 20, 20, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1175 (Batch (None, 20, 20, 256)  768         conv2d_1175[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1175 (Activation)    (None, 20, 20, 256)  0           batch_normalization_1175[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1171 (Conv2D)            (None, 20, 20, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1173 (Conv2D)            (None, 20, 20, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1176 (Conv2D)            (None, 20, 20, 288)  663552      activation_1175[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1171 (Batch (None, 20, 20, 256)  768         conv2d_1171[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1173 (Batch (None, 20, 20, 256)  768         conv2d_1173[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1176 (Batch (None, 20, 20, 288)  864         conv2d_1176[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1171 (Activation)    (None, 20, 20, 256)  0           batch_normalization_1171[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1173 (Activation)    (None, 20, 20, 256)  0           batch_normalization_1173[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1176 (Activation)    (None, 20, 20, 288)  0           batch_normalization_1176[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1172 (Conv2D)            (None, 9, 9, 384)    884736      activation_1171[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1174 (Conv2D)            (None, 9, 9, 288)    663552      activation_1173[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1177 (Conv2D)            (None, 9, 9, 320)    829440      activation_1176[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1172 (Batch (None, 9, 9, 384)    1152        conv2d_1172[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1174 (Batch (None, 9, 9, 288)    864         conv2d_1174[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1177 (Batch (None, 9, 9, 320)    960         conv2d_1177[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1172 (Activation)    (None, 9, 9, 384)    0           batch_normalization_1172[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1174 (Activation)    (None, 9, 9, 288)    0           batch_normalization_1174[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1177 (Activation)    (None, 9, 9, 320)    0           batch_normalization_1177[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling2D) (None, 9, 9, 1088)   0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, 9, 9, 2080)   0           activation_1172[0][0]            \n",
            "                                                                 activation_1174[0][0]            \n",
            "                                                                 activation_1177[0][0]            \n",
            "                                                                 max_pooling2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1179 (Conv2D)            (None, 9, 9, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1179 (Batch (None, 9, 9, 192)    576         conv2d_1179[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1179 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1179[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1180 (Conv2D)            (None, 9, 9, 224)    129024      activation_1179[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1180 (Batch (None, 9, 9, 224)    672         conv2d_1180[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1180 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1180[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1178 (Conv2D)            (None, 9, 9, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1181 (Conv2D)            (None, 9, 9, 256)    172032      activation_1180[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1178 (Batch (None, 9, 9, 192)    576         conv2d_1178[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1181 (Batch (None, 9, 9, 256)    768         conv2d_1181[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1178 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1178[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1181 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1181[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1178[0][0]            \n",
            "                                                                 activation_1181[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, 9, 9, 2080)   0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, 9, 9, 2080)   0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1183 (Conv2D)            (None, 9, 9, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1183 (Batch (None, 9, 9, 192)    576         conv2d_1183[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1183 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1183[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1184 (Conv2D)            (None, 9, 9, 224)    129024      activation_1183[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1184 (Batch (None, 9, 9, 224)    672         conv2d_1184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1184 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1184[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1182 (Conv2D)            (None, 9, 9, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1185 (Conv2D)            (None, 9, 9, 256)    172032      activation_1184[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1182 (Batch (None, 9, 9, 192)    576         conv2d_1182[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1185 (Batch (None, 9, 9, 256)    768         conv2d_1185[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1182 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1182[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1185 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1185[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1182[0][0]            \n",
            "                                                                 activation_1185[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, 9, 9, 2080)   0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, 9, 9, 2080)   0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1187 (Conv2D)            (None, 9, 9, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1187 (Batch (None, 9, 9, 192)    576         conv2d_1187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1187 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1187[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1188 (Conv2D)            (None, 9, 9, 224)    129024      activation_1187[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1188 (Batch (None, 9, 9, 224)    672         conv2d_1188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1188 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1188[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1186 (Conv2D)            (None, 9, 9, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1189 (Conv2D)            (None, 9, 9, 256)    172032      activation_1188[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1186 (Batch (None, 9, 9, 192)    576         conv2d_1186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1189 (Batch (None, 9, 9, 256)    768         conv2d_1189[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1186 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1186[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1189 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1189[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1186[0][0]            \n",
            "                                                                 activation_1189[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, 9, 9, 2080)   0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, 9, 9, 2080)   0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1191 (Conv2D)            (None, 9, 9, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1191 (Batch (None, 9, 9, 192)    576         conv2d_1191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1191 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1191[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1192 (Conv2D)            (None, 9, 9, 224)    129024      activation_1191[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1192 (Batch (None, 9, 9, 224)    672         conv2d_1192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1192 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1192[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1190 (Conv2D)            (None, 9, 9, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1193 (Conv2D)            (None, 9, 9, 256)    172032      activation_1192[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1190 (Batch (None, 9, 9, 192)    576         conv2d_1190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1193 (Batch (None, 9, 9, 256)    768         conv2d_1193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1190 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1190[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1193 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1193[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1190[0][0]            \n",
            "                                                                 activation_1193[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, 9, 9, 2080)   0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, 9, 9, 2080)   0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1195 (Conv2D)            (None, 9, 9, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1195 (Batch (None, 9, 9, 192)    576         conv2d_1195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1195 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1195[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1196 (Conv2D)            (None, 9, 9, 224)    129024      activation_1195[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1196 (Batch (None, 9, 9, 224)    672         conv2d_1196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1196 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1196[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1194 (Conv2D)            (None, 9, 9, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1197 (Conv2D)            (None, 9, 9, 256)    172032      activation_1196[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1194 (Batch (None, 9, 9, 192)    576         conv2d_1194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1197 (Batch (None, 9, 9, 256)    768         conv2d_1197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1194 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1194[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1197 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1197[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1194[0][0]            \n",
            "                                                                 activation_1197[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 9, 9, 2080)   0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 9, 9, 2080)   0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1199 (Conv2D)            (None, 9, 9, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1199 (Batch (None, 9, 9, 192)    576         conv2d_1199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1199 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1199[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1200 (Conv2D)            (None, 9, 9, 224)    129024      activation_1199[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1200 (Batch (None, 9, 9, 224)    672         conv2d_1200[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1200 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1200[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1198 (Conv2D)            (None, 9, 9, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1201 (Conv2D)            (None, 9, 9, 256)    172032      activation_1200[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1198 (Batch (None, 9, 9, 192)    576         conv2d_1198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1201 (Batch (None, 9, 9, 256)    768         conv2d_1201[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1198 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1198[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1201 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1201[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1198[0][0]            \n",
            "                                                                 activation_1201[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 9, 9, 2080)   0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 9, 9, 2080)   0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1203 (Conv2D)            (None, 9, 9, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1203 (Batch (None, 9, 9, 192)    576         conv2d_1203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1203 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1203[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1204 (Conv2D)            (None, 9, 9, 224)    129024      activation_1203[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1204 (Batch (None, 9, 9, 224)    672         conv2d_1204[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1204 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1204[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1202 (Conv2D)            (None, 9, 9, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1205 (Conv2D)            (None, 9, 9, 256)    172032      activation_1204[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1202 (Batch (None, 9, 9, 192)    576         conv2d_1202[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1205 (Batch (None, 9, 9, 256)    768         conv2d_1205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1202 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1202[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1205 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1205[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1202[0][0]            \n",
            "                                                                 activation_1205[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 9, 9, 2080)   0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 9, 9, 2080)   0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1207 (Conv2D)            (None, 9, 9, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1207 (Batch (None, 9, 9, 192)    576         conv2d_1207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1207 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1207[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1208 (Conv2D)            (None, 9, 9, 224)    129024      activation_1207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1208 (Batch (None, 9, 9, 224)    672         conv2d_1208[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1208 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1208[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1206 (Conv2D)            (None, 9, 9, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1209 (Conv2D)            (None, 9, 9, 256)    172032      activation_1208[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1206 (Batch (None, 9, 9, 192)    576         conv2d_1206[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1209 (Batch (None, 9, 9, 256)    768         conv2d_1209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1206 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1206[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1209 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1209[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1206[0][0]            \n",
            "                                                                 activation_1209[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 9, 9, 2080)   0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 9, 9, 2080)   0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1211 (Conv2D)            (None, 9, 9, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1211 (Batch (None, 9, 9, 192)    576         conv2d_1211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1211 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1211[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1212 (Conv2D)            (None, 9, 9, 224)    129024      activation_1211[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1212 (Batch (None, 9, 9, 224)    672         conv2d_1212[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1212 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1212[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1210 (Conv2D)            (None, 9, 9, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1213 (Conv2D)            (None, 9, 9, 256)    172032      activation_1212[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1210 (Batch (None, 9, 9, 192)    576         conv2d_1210[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1213 (Batch (None, 9, 9, 256)    768         conv2d_1213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1210 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1210[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1213 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1213[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 9, 9, 448)    0           activation_1210[0][0]            \n",
            "                                                                 activation_1213[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 9, 9, 2080)   933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 9, 9, 2080)   0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 9, 9, 2080)   0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1215 (Conv2D)            (None, 9, 9, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1215 (Batch (None, 9, 9, 192)    576         conv2d_1215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1215 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1215[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1216 (Conv2D)            (None, 9, 9, 224)    129024      activation_1215[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1216 (Batch (None, 9, 9, 224)    672         conv2d_1216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1216 (Activation)    (None, 9, 9, 224)    0           batch_normalization_1216[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1214 (Conv2D)            (None, 9, 9, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1217 (Conv2D)            (None, 9, 9, 256)    172032      activation_1216[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1214 (Batch (None, 9, 9, 192)    576         conv2d_1214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1217 (Batch (None, 9, 9, 256)    768         conv2d_1217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1214 (Activation)    (None, 9, 9, 192)    0           batch_normalization_1214[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1217 (Activation)    (None, 9, 9, 256)    0           batch_normalization_1217[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 9, 9, 448)    0           activation_1214[0][0]            \n",
            "                                                                 activation_1217[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 9, 9, 2080)   933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 9, 9, 2080)   0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 9, 9, 1536)   3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 9, 9, 1536)   4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 9, 9, 1536)   0           conv_7b_bn[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 54,336,736\n",
            "Trainable params: 54,276,192\n",
            "Non-trainable params: 60,544\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I0CEXaHbz7O"
      },
      "source": [
        "for layer in pre_model.layers[:-4]:\n",
        "    layer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OODBTnIb3LL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8efd5b7c-a1fa-43d8-a736-142f699801a9"
      },
      "source": [
        "# train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                    rescale=1./255, \n",
        "                    rotation_range=13, \n",
        "                    width_shift_range=.12, \n",
        "                    height_shift_range=.12, \n",
        "                    horizontal_flip=False, \n",
        "                    zoom_range=0.4\n",
        "                    )\n",
        "\n",
        "validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "                                                batch_size=batch_size, \n",
        "                                                directory=train_dir, \n",
        "                                                shuffle=True, \n",
        "                                                class_mode='categorical',\n",
        "                                                target_size=(IMG_SHAPE,IMG_SHAPE))\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size, \n",
        "                                                              directory=validation_dir, \n",
        "                                                              class_mode='categorical',\n",
        "                                                              target_size=(IMG_SHAPE,IMG_SHAPE),shuffle=True) #(224,224)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 155100 images belonging to 12 classes.\n",
            "Found 19515 images belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT-3vZtKcB7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "13b81b86-4d0e-451e-e619-464e3f730cea"
      },
      "source": [
        "\n",
        "model_fine = tf.keras.models.Sequential()\n",
        "\n",
        "model_fine.add(pre_model)\n",
        "model_fine.add(tf.keras.layers.LayerNormalization(axis=1 , center=True , scale=True))\n",
        "model_fine.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#model_fine.add(tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.01)))\n",
        "\n",
        "#model_fine.add(tf.keras.layers.Dropout(0.15))\n",
        "#model_fine.add(tf.keras.layers.Dense(32, activation='relu',kernel_regularizer=l2(0.01)))\n",
        "model_fine.add(tf.keras.layers.Dropout(0.2))\n",
        "model_fine.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
        "\n",
        "model_fine.summary()\n",
        "#pre_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Model)  (None, 9, 9, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "layer_normalization_3 (Layer (None, 9, 9, 1536)        18        \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 124416)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 124416)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 12)                1493004   \n",
            "=================================================================\n",
            "Total params: 55,829,758\n",
            "Trainable params: 4,689,438\n",
            "Non-trainable params: 51,140,320\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TBCJ_huSUe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "f0ee2607-492e-41d3-d357-dc5a535a58e3"
      },
      "source": [
        "model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=10, steps_per_epoch=20, validation_steps=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 155s 8s/step - loss: 3.2581 - categorical_accuracy: 0.0984 - val_loss: 2.8895 - val_categorical_accuracy: 0.1500\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 154s 8s/step - loss: 2.9767 - categorical_accuracy: 0.1453 - val_loss: 2.7056 - val_categorical_accuracy: 0.1887\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 158s 8s/step - loss: 2.8201 - categorical_accuracy: 0.1945 - val_loss: 2.5815 - val_categorical_accuracy: 0.2313\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 158s 8s/step - loss: 2.7155 - categorical_accuracy: 0.2211 - val_loss: 2.4792 - val_categorical_accuracy: 0.2684\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 152s 8s/step - loss: 2.6472 - categorical_accuracy: 0.2477 - val_loss: 2.4640 - val_categorical_accuracy: 0.2758\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 153s 8s/step - loss: 2.5360 - categorical_accuracy: 0.2742 - val_loss: 2.3632 - val_categorical_accuracy: 0.3145\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 2.5282 - categorical_accuracy: 0.2832"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU9sY0EucE9C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "6f08c867-824f-4448-82e5-fb1590c2e695"
      },
      "source": [
        "learning_rates = [0.00005,0.00001,0.000007,0.000003,0.000001]\n",
        "for lr in learning_rates:\n",
        "    model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "    history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=10, steps_per_epoch=20, validation_steps=20)\n",
        "    print (\"\\t\\t\\t******************* \\t\\t\",lr,\" \\t\\t******************* \\t\\t \\n \\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 250s 12s/step - loss: 2.7178 - categorical_accuracy: 0.3402 - val_loss: 2.4949 - val_categorical_accuracy: 0.3984\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 242s 12s/step - loss: 2.5462 - categorical_accuracy: 0.3805 - val_loss: 2.5073 - val_categorical_accuracy: 0.4082\n",
            "Epoch 3/10\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 2.5500 - categorical_accuracy: 0.3750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-60f677c9fa0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\\t\\t******************* \\t\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \\t\\t******************* \\t\\t \\n \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    850\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1X6keD4OJT1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2ca1dcd-2e82-4bbc-b6ed-4df439b03102"
      },
      "source": [
        "learning_rates = [0.0000005,0.0000001]\n",
        "for lr in learning_rates:\n",
        "    model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "    history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=15, steps_per_epoch=20, validation_steps=20)\n",
        "    print (\"\\t\\t\\t******************* \\t\\t\",lr,\" \\t\\t******************* \\t\\t \\n \\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 49s 2s/step - loss: 1.4485 - categorical_accuracy: 0.6898 - val_loss: 1.3930 - val_categorical_accuracy: 0.7023\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 46s 2s/step - loss: 1.3641 - categorical_accuracy: 0.7180 - val_loss: 1.3642 - val_categorical_accuracy: 0.7078\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 44s 2s/step - loss: 1.4025 - categorical_accuracy: 0.7125 - val_loss: 1.4306 - val_categorical_accuracy: 0.6992\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 46s 2s/step - loss: 1.4335 - categorical_accuracy: 0.6867 - val_loss: 1.3879 - val_categorical_accuracy: 0.7086\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 45s 2s/step - loss: 1.3737 - categorical_accuracy: 0.7234 - val_loss: 1.4151 - val_categorical_accuracy: 0.6922\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 46s 2s/step - loss: 1.4079 - categorical_accuracy: 0.7070 - val_loss: 1.3904 - val_categorical_accuracy: 0.6977\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 47s 2s/step - loss: 1.3985 - categorical_accuracy: 0.7164 - val_loss: 1.4345 - val_categorical_accuracy: 0.6828\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 44s 2s/step - loss: 1.4156 - categorical_accuracy: 0.7000 - val_loss: 1.3848 - val_categorical_accuracy: 0.7180\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 47s 2s/step - loss: 1.3573 - categorical_accuracy: 0.7266 - val_loss: 1.3944 - val_categorical_accuracy: 0.7070\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.3700 - categorical_accuracy: 0.7289 - val_loss: 1.4390 - val_categorical_accuracy: 0.6820\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 45s 2s/step - loss: 1.3971 - categorical_accuracy: 0.7125 - val_loss: 1.4683 - val_categorical_accuracy: 0.6859\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 47s 2s/step - loss: 1.4116 - categorical_accuracy: 0.7070 - val_loss: 1.4400 - val_categorical_accuracy: 0.6906\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 44s 2s/step - loss: 1.3827 - categorical_accuracy: 0.7047 - val_loss: 1.3885 - val_categorical_accuracy: 0.7227\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 47s 2s/step - loss: 1.4103 - categorical_accuracy: 0.7266 - val_loss: 1.4376 - val_categorical_accuracy: 0.6789\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 45s 2s/step - loss: 1.3582 - categorical_accuracy: 0.7352 - val_loss: 1.4015 - val_categorical_accuracy: 0.6953\n",
            "\t\t\t******************* \t\t 5e-07  \t\t******************* \t\t \n",
            " \n",
            "\n",
            "Epoch 1/15\n",
            "20/20 [==============================] - 51s 3s/step - loss: 1.3643 - categorical_accuracy: 0.7188 - val_loss: 1.4132 - val_categorical_accuracy: 0.7078\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 46s 2s/step - loss: 1.3778 - categorical_accuracy: 0.7094 - val_loss: 1.4070 - val_categorical_accuracy: 0.6984\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 45s 2s/step - loss: 1.3768 - categorical_accuracy: 0.7094 - val_loss: 1.3830 - val_categorical_accuracy: 0.7172\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 47s 2s/step - loss: 1.4056 - categorical_accuracy: 0.7063 - val_loss: 1.4240 - val_categorical_accuracy: 0.6953\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 46s 2s/step - loss: 1.3852 - categorical_accuracy: 0.7008 - val_loss: 1.3881 - val_categorical_accuracy: 0.6844\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 46s 2s/step - loss: 1.4119 - categorical_accuracy: 0.6836 - val_loss: 1.4165 - val_categorical_accuracy: 0.7023\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 46s 2s/step - loss: 1.3894 - categorical_accuracy: 0.7102 - val_loss: 1.4191 - val_categorical_accuracy: 0.6820\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 44s 2s/step - loss: 1.3330 - categorical_accuracy: 0.7266 - val_loss: 1.4114 - val_categorical_accuracy: 0.6953\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 44s 2s/step - loss: 1.4129 - categorical_accuracy: 0.7031 - val_loss: 1.4088 - val_categorical_accuracy: 0.6922\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 46s 2s/step - loss: 1.3912 - categorical_accuracy: 0.7031 - val_loss: 1.4025 - val_categorical_accuracy: 0.7000\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 44s 2s/step - loss: 1.3634 - categorical_accuracy: 0.7234 - val_loss: 1.3962 - val_categorical_accuracy: 0.7188\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 45s 2s/step - loss: 1.3975 - categorical_accuracy: 0.7047 - val_loss: 1.3883 - val_categorical_accuracy: 0.7039\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 45s 2s/step - loss: 1.4128 - categorical_accuracy: 0.6945 - val_loss: 1.4222 - val_categorical_accuracy: 0.6984\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 44s 2s/step - loss: 1.3771 - categorical_accuracy: 0.7156 - val_loss: 1.4354 - val_categorical_accuracy: 0.6944\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 43s 2s/step - loss: 1.3706 - categorical_accuracy: 0.7227 - val_loss: 1.4505 - val_categorical_accuracy: 0.6734\n",
            "\t\t\t******************* \t\t 1e-07  \t\t******************* \t\t \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMsKEyibuZtS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "514394e3-46b4-4371-b96a-5a3799bde147"
      },
      "source": [
        "\n",
        "model_fine = tf.keras.models.Sequential()\n",
        "\n",
        "model_fine.add(pre_model)\n",
        "model_fine.add(tf.keras.layers.LayerNormalization(axis=1 , center=True , scale=True))\n",
        "model_fine.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model_fine.add(tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model_fine.add(tf.keras.layers.Dropout(0.25))\n",
        "model_fine.add(tf.keras.layers.Dense(32, activation='relu',kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n",
        "model_fine.add(tf.keras.layers.Dropout(0.15))\n",
        "model_fine.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
        "\n",
        "model_fine.summary()\n",
        "#pre_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Model)  (None, 8, 8, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "layer_normalization_8 (Layer (None, 8, 8, 1536)        16        \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 98304)             0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               12583040  \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 12)                396       \n",
            "=================================================================\n",
            "Total params: 66,924,316\n",
            "Trainable params: 16,717,916\n",
            "Non-trainable params: 50,206,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92Baj63_POzq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "981fac88-25dc-4408-afc3-42e0ba62fefa"
      },
      "source": [
        "learning_rates = [0.001,0.0007,0.0003,0.0001,0.00007,0.00003,0.00001,0.000007,0.000003,0.000001,0.0000005,0.0000001]\n",
        "for lr in learning_rates:\n",
        "    model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "    history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=10, steps_per_epoch=20, validation_steps=20)\n",
        "    print (\"\\t\\t\\t******************* \\t\\t\",lr,\" \\t\\t******************* \\t\\t \\n \\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 52s 3s/step - loss: 10.7651 - categorical_accuracy: 0.1992 - val_loss: 11.2721 - val_categorical_accuracy: 0.2188\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 45s 2s/step - loss: 11.4963 - categorical_accuracy: 0.1898 - val_loss: 11.0244 - val_categorical_accuracy: 0.2445\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 10.6406 - categorical_accuracy: 0.2234 - val_loss: 9.7113 - val_categorical_accuracy: 0.2922\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 44s 2s/step - loss: 9.3570 - categorical_accuracy: 0.2340 - val_loss: 8.6478 - val_categorical_accuracy: 0.3383\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 8.3197 - categorical_accuracy: 0.2547 - val_loss: 7.6023 - val_categorical_accuracy: 0.3711\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 45s 2s/step - loss: 7.5030 - categorical_accuracy: 0.2977 - val_loss: 6.9107 - val_categorical_accuracy: 0.4141\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 6.9235 - categorical_accuracy: 0.3172 - val_loss: 6.5295 - val_categorical_accuracy: 0.4195\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 44s 2s/step - loss: 6.6074 - categorical_accuracy: 0.3438 - val_loss: 6.0915 - val_categorical_accuracy: 0.4719\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 45s 2s/step - loss: 6.3183 - categorical_accuracy: 0.3352 - val_loss: 5.8378 - val_categorical_accuracy: 0.4695\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 5.8718 - categorical_accuracy: 0.3930 - val_loss: 5.4006 - val_categorical_accuracy: 0.4969\n",
            "\t\t\t******************* \t\t 0.001  \t\t******************* \t\t \n",
            " \n",
            "\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 50s 2s/step - loss: 5.7152 - categorical_accuracy: 0.3773 - val_loss: 5.5407 - val_categorical_accuracy: 0.4695\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 5.6872 - categorical_accuracy: 0.4070 - val_loss: 5.2907 - val_categorical_accuracy: 0.5195\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 5.4001 - categorical_accuracy: 0.4344 - val_loss: 5.0067 - val_categorical_accuracy: 0.5344\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 5.1059 - categorical_accuracy: 0.4578 - val_loss: 4.7302 - val_categorical_accuracy: 0.5672\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 4.8237 - categorical_accuracy: 0.4812 - val_loss: 4.4677 - val_categorical_accuracy: 0.5432\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 4.5330 - categorical_accuracy: 0.4789 - val_loss: 4.1885 - val_categorical_accuracy: 0.5781\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 4.3810 - categorical_accuracy: 0.4977 - val_loss: 4.1460 - val_categorical_accuracy: 0.5531\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 4.1678 - categorical_accuracy: 0.5430 - val_loss: 4.0708 - val_categorical_accuracy: 0.5703\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 4.1797 - categorical_accuracy: 0.5203 - val_loss: 3.9194 - val_categorical_accuracy: 0.5797\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 4.1410 - categorical_accuracy: 0.5328 - val_loss: 3.8490 - val_categorical_accuracy: 0.6125\n",
            "\t\t\t******************* \t\t 0.0007  \t\t******************* \t\t \n",
            " \n",
            "\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 53s 3s/step - loss: 3.9147 - categorical_accuracy: 0.5422 - val_loss: 3.5619 - val_categorical_accuracy: 0.6156\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 45s 2s/step - loss: 3.6102 - categorical_accuracy: 0.5625 - val_loss: 3.3511 - val_categorical_accuracy: 0.6484\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 3.3860 - categorical_accuracy: 0.5734 - val_loss: 3.1172 - val_categorical_accuracy: 0.6461\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 3.2017 - categorical_accuracy: 0.5844 - val_loss: 2.9770 - val_categorical_accuracy: 0.6578\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 3.0932 - categorical_accuracy: 0.5711 - val_loss: 2.8301 - val_categorical_accuracy: 0.6758\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 2.9663 - categorical_accuracy: 0.6086 - val_loss: 2.7669 - val_categorical_accuracy: 0.6844\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 2.8578 - categorical_accuracy: 0.5969 - val_loss: 2.6417 - val_categorical_accuracy: 0.6945\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 2.7695 - categorical_accuracy: 0.6234 - val_loss: 2.5656 - val_categorical_accuracy: 0.6789\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 2.6414 - categorical_accuracy: 0.6328 - val_loss: 2.5373 - val_categorical_accuracy: 0.6844\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 2.6873 - categorical_accuracy: 0.6133 - val_loss: 2.4970 - val_categorical_accuracy: 0.6672\n",
            "\t\t\t******************* \t\t 0.0003  \t\t******************* \t\t \n",
            " \n",
            "\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 51s 3s/step - loss: 2.5115 - categorical_accuracy: 0.6359 - val_loss: 2.3409 - val_categorical_accuracy: 0.6960\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 2.5178 - categorical_accuracy: 0.6352 - val_loss: 2.3056 - val_categorical_accuracy: 0.7102\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 2.4324 - categorical_accuracy: 0.6484 - val_loss: 2.3002 - val_categorical_accuracy: 0.6852\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 2.3583 - categorical_accuracy: 0.6562 - val_loss: 2.2112 - val_categorical_accuracy: 0.7016\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 2.3152 - categorical_accuracy: 0.6516 - val_loss: 2.1315 - val_categorical_accuracy: 0.7414\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 2.3379 - categorical_accuracy: 0.6266 - val_loss: 2.1574 - val_categorical_accuracy: 0.7070\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 2.2218 - categorical_accuracy: 0.6461 - val_loss: 2.0904 - val_categorical_accuracy: 0.7164\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 2.1552 - categorical_accuracy: 0.6609 - val_loss: 2.1075 - val_categorical_accuracy: 0.7102\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 46s 2s/step - loss: 2.1640 - categorical_accuracy: 0.6617 - val_loss: 2.0149 - val_categorical_accuracy: 0.7359\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 2.1005 - categorical_accuracy: 0.6797 - val_loss: 2.0322 - val_categorical_accuracy: 0.6977\n",
            "\t\t\t******************* \t\t 0.0001  \t\t******************* \t\t \n",
            " \n",
            "\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 55s 3s/step - loss: 2.1150 - categorical_accuracy: 0.6672 - val_loss: 1.9958 - val_categorical_accuracy: 0.7109\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 50s 2s/step - loss: 2.0252 - categorical_accuracy: 0.6695 - val_loss: 1.9271 - val_categorical_accuracy: 0.7273\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 2.0050 - categorical_accuracy: 0.6687 - val_loss: 1.9031 - val_categorical_accuracy: 0.7188\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 1.9814 - categorical_accuracy: 0.6781 - val_loss: 1.9313 - val_categorical_accuracy: 0.7266\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 1.9722 - categorical_accuracy: 0.6719 - val_loss: 1.8864 - val_categorical_accuracy: 0.7258\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.9787 - categorical_accuracy: 0.6602 - val_loss: 1.7806 - val_categorical_accuracy: 0.7258\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.9162 - categorical_accuracy: 0.7008 - val_loss: 1.8037 - val_categorical_accuracy: 0.7276\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 1.9048 - categorical_accuracy: 0.6969 - val_loss: 1.8535 - val_categorical_accuracy: 0.6930\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.9348 - categorical_accuracy: 0.6719 - val_loss: 1.7784 - val_categorical_accuracy: 0.7336\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 1.8393 - categorical_accuracy: 0.6844 - val_loss: 1.7423 - val_categorical_accuracy: 0.7328\n",
            "\t\t\t******************* \t\t 7e-05  \t\t******************* \t\t \n",
            " \n",
            "\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 51s 3s/step - loss: 1.8643 - categorical_accuracy: 0.6680 - val_loss: 1.7705 - val_categorical_accuracy: 0.7375\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.7902 - categorical_accuracy: 0.6977 - val_loss: 1.7788 - val_categorical_accuracy: 0.7203\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.7764 - categorical_accuracy: 0.6953 - val_loss: 1.7522 - val_categorical_accuracy: 0.7266\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.8297 - categorical_accuracy: 0.6773 - val_loss: 1.7076 - val_categorical_accuracy: 0.7383\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.7718 - categorical_accuracy: 0.7094 - val_loss: 1.7141 - val_categorical_accuracy: 0.7453\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 1.8403 - categorical_accuracy: 0.6758 - val_loss: 1.6979 - val_categorical_accuracy: 0.7383\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 47s 2s/step - loss: 1.7857 - categorical_accuracy: 0.6953 - val_loss: 1.6215 - val_categorical_accuracy: 0.7648\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 49s 2s/step - loss: 1.7669 - categorical_accuracy: 0.6953 - val_loss: 1.6729 - val_categorical_accuracy: 0.7312\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 48s 2s/step - loss: 1.7716 - categorical_accuracy: 0.6805 - val_loss: 1.6585 - val_categorical_accuracy: 0.7563\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 50s 2s/step - loss: 1.7302 - categorical_accuracy: 0.6898 - val_loss: 1.6356 - val_categorical_accuracy: 0.7492\n",
            "\t\t\t******************* \t\t 3e-05  \t\t******************* \t\t \n",
            " \n",
            "\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.7291 - categorical_accuracy: 0.6891"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-af664b070a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\\t\\t******************* \\t\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \\t\\t******************* \\t\\t \\n \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    876\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                 step_num=step):\n\u001b[1;32m   1083\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA3-EPhTukSO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0f6962d-c8d1-4c89-d01e-6e7ee51a0e74"
      },
      "source": [
        "pre_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet',input_shape=(299, 299, 3),classes=12)\n",
        "pre_model.summary()\n",
        "\n",
        "for layer in pre_model.layers[:-1]:\n",
        "    layer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_resnet_v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 149, 149, 32) 864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_406 (BatchN (None, 149, 149, 32) 96          conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, 149, 149, 32) 0           batch_normalization_406[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 147, 147, 32) 9216        activation_406[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_407 (BatchN (None, 147, 147, 32) 96          conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_407 (Activation)     (None, 147, 147, 32) 0           batch_normalization_407[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 147, 147, 64) 18432       activation_407[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_408 (BatchN (None, 147, 147, 64) 192         conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_408 (Activation)     (None, 147, 147, 64) 0           batch_normalization_408[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_409 (BatchN (None, 73, 73, 80)   240         conv2d_409[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_409 (Activation)     (None, 73, 73, 80)   0           batch_normalization_409[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 71, 71, 192)  138240      activation_409[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_410 (BatchN (None, 71, 71, 192)  576         conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_410 (Activation)     (None, 71, 71, 192)  0           batch_normalization_410[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_410[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_414 (BatchN (None, 35, 35, 64)   192         conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_414 (Activation)     (None, 35, 35, 64)   0           batch_normalization_414[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 35, 35, 96)   55296       activation_414[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_412 (BatchN (None, 35, 35, 48)   144         conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_415 (BatchN (None, 35, 35, 96)   288         conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_412 (Activation)     (None, 35, 35, 48)   0           batch_normalization_412[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_415 (Activation)     (None, 35, 35, 96)   0           batch_normalization_415[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 35, 35, 96)   18432       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 35, 35, 64)   76800       activation_412[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 35, 35, 96)   82944       activation_415[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 35, 35, 64)   12288       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_411 (BatchN (None, 35, 35, 96)   288         conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_413 (BatchN (None, 35, 35, 64)   192         conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_416 (BatchN (None, 35, 35, 96)   288         conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_417 (BatchN (None, 35, 35, 64)   192         conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_411 (Activation)     (None, 35, 35, 96)   0           batch_normalization_411[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_413 (Activation)     (None, 35, 35, 64)   0           batch_normalization_413[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 35, 35, 96)   0           batch_normalization_416[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 35, 35, 64)   0           batch_normalization_417[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_411[0][0]             \n",
            "                                                                 activation_413[0][0]             \n",
            "                                                                 activation_416[0][0]             \n",
            "                                                                 activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_421 (BatchN (None, 35, 35, 32)   96          conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 35, 35, 32)   0           batch_normalization_421[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 35, 35, 48)   13824       activation_421[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_419 (BatchN (None, 35, 35, 32)   96          conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_422 (BatchN (None, 35, 35, 48)   144         conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 35, 35, 32)   0           batch_normalization_419[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 35, 35, 48)   0           batch_normalization_422[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 35, 35, 32)   9216        activation_419[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 35, 35, 64)   27648       activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_418 (BatchN (None, 35, 35, 32)   96          conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_420 (BatchN (None, 35, 35, 32)   96          conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_423 (BatchN (None, 35, 35, 64)   192         conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 35, 35, 32)   0           batch_normalization_418[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 35, 35, 32)   0           batch_normalization_420[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 35, 35, 64)   0           batch_normalization_423[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_418[0][0]             \n",
            "                                                                 activation_420[0][0]             \n",
            "                                                                 activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_427 (BatchN (None, 35, 35, 32)   96          conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 35, 35, 32)   0           batch_normalization_427[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 35, 35, 48)   13824       activation_427[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_425 (BatchN (None, 35, 35, 32)   96          conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_428 (BatchN (None, 35, 35, 48)   144         conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 35, 35, 32)   0           batch_normalization_425[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 35, 35, 48)   0           batch_normalization_428[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 35, 35, 32)   9216        activation_425[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 35, 35, 64)   27648       activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_424 (BatchN (None, 35, 35, 32)   96          conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_426 (BatchN (None, 35, 35, 32)   96          conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_429 (BatchN (None, 35, 35, 64)   192         conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 35, 35, 32)   0           batch_normalization_424[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 35, 35, 32)   0           batch_normalization_426[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_429 (Activation)     (None, 35, 35, 64)   0           batch_normalization_429[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_424[0][0]             \n",
            "                                                                 activation_426[0][0]             \n",
            "                                                                 activation_429[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_433 (BatchN (None, 35, 35, 32)   96          conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 35, 35, 32)   0           batch_normalization_433[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 35, 35, 48)   13824       activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_431 (BatchN (None, 35, 35, 32)   96          conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_434 (BatchN (None, 35, 35, 48)   144         conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 35, 35, 32)   0           batch_normalization_431[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 35, 35, 48)   0           batch_normalization_434[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 35, 35, 32)   9216        activation_431[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 35, 35, 64)   27648       activation_434[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_430 (BatchN (None, 35, 35, 32)   96          conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_432 (BatchN (None, 35, 35, 32)   96          conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_435 (BatchN (None, 35, 35, 64)   192         conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 35, 35, 32)   0           batch_normalization_430[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 35, 35, 32)   0           batch_normalization_432[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 35, 35, 64)   0           batch_normalization_435[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_430[0][0]             \n",
            "                                                                 activation_432[0][0]             \n",
            "                                                                 activation_435[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_439 (BatchN (None, 35, 35, 32)   96          conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 35, 35, 32)   0           batch_normalization_439[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 35, 35, 48)   13824       activation_439[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_437 (BatchN (None, 35, 35, 32)   96          conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_440 (BatchN (None, 35, 35, 48)   144         conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 35, 35, 32)   0           batch_normalization_437[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 35, 35, 48)   0           batch_normalization_440[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 35, 35, 32)   9216        activation_437[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 35, 35, 64)   27648       activation_440[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_436 (BatchN (None, 35, 35, 32)   96          conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_438 (BatchN (None, 35, 35, 32)   96          conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_441 (BatchN (None, 35, 35, 64)   192         conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 35, 35, 32)   0           batch_normalization_436[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 35, 35, 32)   0           batch_normalization_438[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 35, 35, 64)   0           batch_normalization_441[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_436[0][0]             \n",
            "                                                                 activation_438[0][0]             \n",
            "                                                                 activation_441[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_445 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_445 (BatchN (None, 35, 35, 32)   96          conv2d_445[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_445 (Activation)     (None, 35, 35, 32)   0           batch_normalization_445[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_443 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_446 (Conv2D)             (None, 35, 35, 48)   13824       activation_445[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_443 (BatchN (None, 35, 35, 32)   96          conv2d_443[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_446 (BatchN (None, 35, 35, 48)   144         conv2d_446[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_443 (Activation)     (None, 35, 35, 32)   0           batch_normalization_443[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_446 (Activation)     (None, 35, 35, 48)   0           batch_normalization_446[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_444 (Conv2D)             (None, 35, 35, 32)   9216        activation_443[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_447 (Conv2D)             (None, 35, 35, 64)   27648       activation_446[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_442 (BatchN (None, 35, 35, 32)   96          conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_444 (BatchN (None, 35, 35, 32)   96          conv2d_444[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_447 (BatchN (None, 35, 35, 64)   192         conv2d_447[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_442 (Activation)     (None, 35, 35, 32)   0           batch_normalization_442[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_444 (Activation)     (None, 35, 35, 32)   0           batch_normalization_444[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_447 (Activation)     (None, 35, 35, 64)   0           batch_normalization_447[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_442[0][0]             \n",
            "                                                                 activation_444[0][0]             \n",
            "                                                                 activation_447[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_451 (BatchN (None, 35, 35, 32)   96          conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_451 (Activation)     (None, 35, 35, 32)   0           batch_normalization_451[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_449 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 35, 35, 48)   13824       activation_451[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_449 (BatchN (None, 35, 35, 32)   96          conv2d_449[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_452 (BatchN (None, 35, 35, 48)   144         conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_449 (Activation)     (None, 35, 35, 32)   0           batch_normalization_449[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_452 (Activation)     (None, 35, 35, 48)   0           batch_normalization_452[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 35, 35, 32)   9216        activation_449[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 35, 35, 64)   27648       activation_452[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_448 (BatchN (None, 35, 35, 32)   96          conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_450 (BatchN (None, 35, 35, 32)   96          conv2d_450[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_453 (BatchN (None, 35, 35, 64)   192         conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_448 (Activation)     (None, 35, 35, 32)   0           batch_normalization_448[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_450 (Activation)     (None, 35, 35, 32)   0           batch_normalization_450[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_453 (Activation)     (None, 35, 35, 64)   0           batch_normalization_453[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_448[0][0]             \n",
            "                                                                 activation_450[0][0]             \n",
            "                                                                 activation_453[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_457 (BatchN (None, 35, 35, 32)   96          conv2d_457[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_457 (Activation)     (None, 35, 35, 32)   0           batch_normalization_457[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 35, 35, 48)   13824       activation_457[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_455 (BatchN (None, 35, 35, 32)   96          conv2d_455[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_458 (BatchN (None, 35, 35, 48)   144         conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_455 (Activation)     (None, 35, 35, 32)   0           batch_normalization_455[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_458 (Activation)     (None, 35, 35, 48)   0           batch_normalization_458[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 35, 35, 32)   9216        activation_455[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 35, 35, 64)   27648       activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_454 (BatchN (None, 35, 35, 32)   96          conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_456 (BatchN (None, 35, 35, 32)   96          conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_459 (BatchN (None, 35, 35, 64)   192         conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_454 (Activation)     (None, 35, 35, 32)   0           batch_normalization_454[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_456 (Activation)     (None, 35, 35, 32)   0           batch_normalization_456[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_459 (Activation)     (None, 35, 35, 64)   0           batch_normalization_459[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_454[0][0]             \n",
            "                                                                 activation_456[0][0]             \n",
            "                                                                 activation_459[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_463 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_463 (BatchN (None, 35, 35, 32)   96          conv2d_463[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_463 (Activation)     (None, 35, 35, 32)   0           batch_normalization_463[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_461 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_464 (Conv2D)             (None, 35, 35, 48)   13824       activation_463[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_461 (BatchN (None, 35, 35, 32)   96          conv2d_461[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_464 (BatchN (None, 35, 35, 48)   144         conv2d_464[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_461 (Activation)     (None, 35, 35, 32)   0           batch_normalization_461[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_464 (Activation)     (None, 35, 35, 48)   0           batch_normalization_464[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_462 (Conv2D)             (None, 35, 35, 32)   9216        activation_461[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_465 (Conv2D)             (None, 35, 35, 64)   27648       activation_464[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_460 (BatchN (None, 35, 35, 32)   96          conv2d_460[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_462 (BatchN (None, 35, 35, 32)   96          conv2d_462[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_465 (BatchN (None, 35, 35, 64)   192         conv2d_465[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_460 (Activation)     (None, 35, 35, 32)   0           batch_normalization_460[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_462 (Activation)     (None, 35, 35, 32)   0           batch_normalization_462[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_465 (Activation)     (None, 35, 35, 64)   0           batch_normalization_465[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_460[0][0]             \n",
            "                                                                 activation_462[0][0]             \n",
            "                                                                 activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_469 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_469 (BatchN (None, 35, 35, 32)   96          conv2d_469[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_469 (Activation)     (None, 35, 35, 32)   0           batch_normalization_469[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_467 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_470 (Conv2D)             (None, 35, 35, 48)   13824       activation_469[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_467 (BatchN (None, 35, 35, 32)   96          conv2d_467[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_470 (BatchN (None, 35, 35, 48)   144         conv2d_470[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_467 (Activation)     (None, 35, 35, 32)   0           batch_normalization_467[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_470 (Activation)     (None, 35, 35, 48)   0           batch_normalization_470[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_466 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_468 (Conv2D)             (None, 35, 35, 32)   9216        activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_471 (Conv2D)             (None, 35, 35, 64)   27648       activation_470[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_466 (BatchN (None, 35, 35, 32)   96          conv2d_466[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_468 (BatchN (None, 35, 35, 32)   96          conv2d_468[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_471 (BatchN (None, 35, 35, 64)   192         conv2d_471[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_466 (Activation)     (None, 35, 35, 32)   0           batch_normalization_466[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_468 (Activation)     (None, 35, 35, 32)   0           batch_normalization_468[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, 35, 35, 64)   0           batch_normalization_471[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_466[0][0]             \n",
            "                                                                 activation_468[0][0]             \n",
            "                                                                 activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_475 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_475 (BatchN (None, 35, 35, 32)   96          conv2d_475[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_475 (Activation)     (None, 35, 35, 32)   0           batch_normalization_475[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_473 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_476 (Conv2D)             (None, 35, 35, 48)   13824       activation_475[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_473 (BatchN (None, 35, 35, 32)   96          conv2d_473[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_476 (BatchN (None, 35, 35, 48)   144         conv2d_476[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, 35, 35, 32)   0           batch_normalization_473[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, 35, 35, 48)   0           batch_normalization_476[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_472 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_474 (Conv2D)             (None, 35, 35, 32)   9216        activation_473[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_477 (Conv2D)             (None, 35, 35, 64)   27648       activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_472 (BatchN (None, 35, 35, 32)   96          conv2d_472[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_474 (BatchN (None, 35, 35, 32)   96          conv2d_474[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_477 (BatchN (None, 35, 35, 64)   192         conv2d_477[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, 35, 35, 32)   0           batch_normalization_472[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, 35, 35, 32)   0           batch_normalization_474[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, 35, 35, 64)   0           batch_normalization_477[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_472[0][0]             \n",
            "                                                                 activation_474[0][0]             \n",
            "                                                                 activation_477[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_479 (Conv2D)             (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_479 (BatchN (None, 35, 35, 256)  768         conv2d_479[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, 35, 35, 256)  0           batch_normalization_479[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_480 (Conv2D)             (None, 35, 35, 256)  589824      activation_479[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_480 (BatchN (None, 35, 35, 256)  768         conv2d_480[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, 35, 35, 256)  0           batch_normalization_480[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_478 (Conv2D)             (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_481 (Conv2D)             (None, 17, 17, 384)  884736      activation_480[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_478 (BatchN (None, 17, 17, 384)  1152        conv2d_478[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_481 (BatchN (None, 17, 17, 384)  1152        conv2d_481[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, 17, 17, 384)  0           batch_normalization_478[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, 17, 17, 384)  0           batch_normalization_481[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_478[0][0]             \n",
            "                                                                 activation_481[0][0]             \n",
            "                                                                 max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_483 (Conv2D)             (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_483 (BatchN (None, 17, 17, 128)  384         conv2d_483[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, 17, 17, 128)  0           batch_normalization_483[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_484 (Conv2D)             (None, 17, 17, 160)  143360      activation_483[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_484 (BatchN (None, 17, 17, 160)  480         conv2d_484[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, 17, 17, 160)  0           batch_normalization_484[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_482 (Conv2D)             (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_485 (Conv2D)             (None, 17, 17, 192)  215040      activation_484[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_482 (BatchN (None, 17, 17, 192)  576         conv2d_482[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_485 (BatchN (None, 17, 17, 192)  576         conv2d_485[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, 17, 17, 192)  0           batch_normalization_482[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, 17, 17, 192)  0           batch_normalization_485[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_482[0][0]             \n",
            "                                                                 activation_485[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_487 (Conv2D)             (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_487 (BatchN (None, 17, 17, 128)  384         conv2d_487[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, 17, 17, 128)  0           batch_normalization_487[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_488 (Conv2D)             (None, 17, 17, 160)  143360      activation_487[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_488 (BatchN (None, 17, 17, 160)  480         conv2d_488[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, 17, 17, 160)  0           batch_normalization_488[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_486 (Conv2D)             (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, 17, 17, 192)  215040      activation_488[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_486 (BatchN (None, 17, 17, 192)  576         conv2d_486[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_489 (BatchN (None, 17, 17, 192)  576         conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, 17, 17, 192)  0           batch_normalization_486[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, 17, 17, 192)  0           batch_normalization_489[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_486[0][0]             \n",
            "                                                                 activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_491 (BatchN (None, 17, 17, 128)  384         conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, 17, 17, 128)  0           batch_normalization_491[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, 17, 17, 160)  143360      activation_491[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_492 (BatchN (None, 17, 17, 160)  480         conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, 17, 17, 160)  0           batch_normalization_492[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, 17, 17, 192)  215040      activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_490 (BatchN (None, 17, 17, 192)  576         conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_493 (BatchN (None, 17, 17, 192)  576         conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, 17, 17, 192)  0           batch_normalization_490[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, 17, 17, 192)  0           batch_normalization_493[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_490[0][0]             \n",
            "                                                                 activation_493[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_495 (BatchN (None, 17, 17, 128)  384         conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, 17, 17, 128)  0           batch_normalization_495[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, 17, 17, 160)  143360      activation_495[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_496 (BatchN (None, 17, 17, 160)  480         conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, 17, 17, 160)  0           batch_normalization_496[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_497 (Conv2D)             (None, 17, 17, 192)  215040      activation_496[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_494 (BatchN (None, 17, 17, 192)  576         conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_497 (BatchN (None, 17, 17, 192)  576         conv2d_497[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, 17, 17, 192)  0           batch_normalization_494[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, 17, 17, 192)  0           batch_normalization_497[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_494[0][0]             \n",
            "                                                                 activation_497[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_499 (Conv2D)             (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_499 (BatchN (None, 17, 17, 128)  384         conv2d_499[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, 17, 17, 128)  0           batch_normalization_499[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_500 (Conv2D)             (None, 17, 17, 160)  143360      activation_499[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_500 (BatchN (None, 17, 17, 160)  480         conv2d_500[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, 17, 17, 160)  0           batch_normalization_500[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_498 (Conv2D)             (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_501 (Conv2D)             (None, 17, 17, 192)  215040      activation_500[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_498 (BatchN (None, 17, 17, 192)  576         conv2d_498[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_501 (BatchN (None, 17, 17, 192)  576         conv2d_501[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, 17, 17, 192)  0           batch_normalization_498[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, 17, 17, 192)  0           batch_normalization_501[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_498[0][0]             \n",
            "                                                                 activation_501[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_503 (Conv2D)             (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_503 (BatchN (None, 17, 17, 128)  384         conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_503 (Activation)     (None, 17, 17, 128)  0           batch_normalization_503[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_504 (Conv2D)             (None, 17, 17, 160)  143360      activation_503[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_504 (BatchN (None, 17, 17, 160)  480         conv2d_504[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_504 (Activation)     (None, 17, 17, 160)  0           batch_normalization_504[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_505 (Conv2D)             (None, 17, 17, 192)  215040      activation_504[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_502 (BatchN (None, 17, 17, 192)  576         conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_505 (BatchN (None, 17, 17, 192)  576         conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, 17, 17, 192)  0           batch_normalization_502[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_505 (Activation)     (None, 17, 17, 192)  0           batch_normalization_505[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_502[0][0]             \n",
            "                                                                 activation_505[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_507 (BatchN (None, 17, 17, 128)  384         conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_507 (Activation)     (None, 17, 17, 128)  0           batch_normalization_507[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, 17, 17, 160)  143360      activation_507[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_508 (BatchN (None, 17, 17, 160)  480         conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_508 (Activation)     (None, 17, 17, 160)  0           batch_normalization_508[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_506 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, 17, 17, 192)  215040      activation_508[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_506 (BatchN (None, 17, 17, 192)  576         conv2d_506[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_509 (BatchN (None, 17, 17, 192)  576         conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_506 (Activation)     (None, 17, 17, 192)  0           batch_normalization_506[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_509 (Activation)     (None, 17, 17, 192)  0           batch_normalization_509[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_506[0][0]             \n",
            "                                                                 activation_509[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_511 (BatchN (None, 17, 17, 128)  384         conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_511 (Activation)     (None, 17, 17, 128)  0           batch_normalization_511[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, 17, 17, 160)  143360      activation_511[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_512 (BatchN (None, 17, 17, 160)  480         conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_512 (Activation)     (None, 17, 17, 160)  0           batch_normalization_512[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, 17, 17, 192)  215040      activation_512[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_510 (BatchN (None, 17, 17, 192)  576         conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_513 (BatchN (None, 17, 17, 192)  576         conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_510 (Activation)     (None, 17, 17, 192)  0           batch_normalization_510[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_513 (Activation)     (None, 17, 17, 192)  0           batch_normalization_513[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_510[0][0]             \n",
            "                                                                 activation_513[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_515 (BatchN (None, 17, 17, 128)  384         conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_515 (Activation)     (None, 17, 17, 128)  0           batch_normalization_515[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, 17, 17, 160)  143360      activation_515[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_516 (BatchN (None, 17, 17, 160)  480         conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_516 (Activation)     (None, 17, 17, 160)  0           batch_normalization_516[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, 17, 17, 192)  215040      activation_516[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_514 (BatchN (None, 17, 17, 192)  576         conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_517 (BatchN (None, 17, 17, 192)  576         conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_514 (Activation)     (None, 17, 17, 192)  0           batch_normalization_514[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_517 (Activation)     (None, 17, 17, 192)  0           batch_normalization_517[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_514[0][0]             \n",
            "                                                                 activation_517[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_519 (BatchN (None, 17, 17, 128)  384         conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_519 (Activation)     (None, 17, 17, 128)  0           batch_normalization_519[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, 17, 17, 160)  143360      activation_519[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_520 (BatchN (None, 17, 17, 160)  480         conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_520 (Activation)     (None, 17, 17, 160)  0           batch_normalization_520[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, 17, 17, 192)  215040      activation_520[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_518 (BatchN (None, 17, 17, 192)  576         conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_521 (BatchN (None, 17, 17, 192)  576         conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_518 (Activation)     (None, 17, 17, 192)  0           batch_normalization_518[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_521 (Activation)     (None, 17, 17, 192)  0           batch_normalization_521[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_518[0][0]             \n",
            "                                                                 activation_521[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_523 (BatchN (None, 17, 17, 128)  384         conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_523 (Activation)     (None, 17, 17, 128)  0           batch_normalization_523[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, 17, 17, 160)  143360      activation_523[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_524 (BatchN (None, 17, 17, 160)  480         conv2d_524[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_524 (Activation)     (None, 17, 17, 160)  0           batch_normalization_524[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, 17, 17, 192)  215040      activation_524[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_522 (BatchN (None, 17, 17, 192)  576         conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_525 (BatchN (None, 17, 17, 192)  576         conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_522 (Activation)     (None, 17, 17, 192)  0           batch_normalization_522[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_525 (Activation)     (None, 17, 17, 192)  0           batch_normalization_525[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_522[0][0]             \n",
            "                                                                 activation_525[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_527 (BatchN (None, 17, 17, 128)  384         conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_527 (Activation)     (None, 17, 17, 128)  0           batch_normalization_527[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_528 (Conv2D)             (None, 17, 17, 160)  143360      activation_527[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_528 (BatchN (None, 17, 17, 160)  480         conv2d_528[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_528 (Activation)     (None, 17, 17, 160)  0           batch_normalization_528[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_529 (Conv2D)             (None, 17, 17, 192)  215040      activation_528[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_526 (BatchN (None, 17, 17, 192)  576         conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_529 (BatchN (None, 17, 17, 192)  576         conv2d_529[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_526 (Activation)     (None, 17, 17, 192)  0           batch_normalization_526[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_529 (Activation)     (None, 17, 17, 192)  0           batch_normalization_529[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_526[0][0]             \n",
            "                                                                 activation_529[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_531 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_531 (BatchN (None, 17, 17, 128)  384         conv2d_531[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_531 (Activation)     (None, 17, 17, 128)  0           batch_normalization_531[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_532 (Conv2D)             (None, 17, 17, 160)  143360      activation_531[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_532 (BatchN (None, 17, 17, 160)  480         conv2d_532[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_532 (Activation)     (None, 17, 17, 160)  0           batch_normalization_532[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_530 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_533 (Conv2D)             (None, 17, 17, 192)  215040      activation_532[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_530 (BatchN (None, 17, 17, 192)  576         conv2d_530[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_533 (BatchN (None, 17, 17, 192)  576         conv2d_533[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_530 (Activation)     (None, 17, 17, 192)  0           batch_normalization_530[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_533 (Activation)     (None, 17, 17, 192)  0           batch_normalization_533[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_530[0][0]             \n",
            "                                                                 activation_533[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_535 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_535 (BatchN (None, 17, 17, 128)  384         conv2d_535[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_535 (Activation)     (None, 17, 17, 128)  0           batch_normalization_535[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_536 (Conv2D)             (None, 17, 17, 160)  143360      activation_535[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_536 (BatchN (None, 17, 17, 160)  480         conv2d_536[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_536 (Activation)     (None, 17, 17, 160)  0           batch_normalization_536[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_534 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_537 (Conv2D)             (None, 17, 17, 192)  215040      activation_536[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_534 (BatchN (None, 17, 17, 192)  576         conv2d_534[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_537 (BatchN (None, 17, 17, 192)  576         conv2d_537[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_534 (Activation)     (None, 17, 17, 192)  0           batch_normalization_534[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_537 (Activation)     (None, 17, 17, 192)  0           batch_normalization_537[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_534[0][0]             \n",
            "                                                                 activation_537[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_539 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_539 (BatchN (None, 17, 17, 128)  384         conv2d_539[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_539 (Activation)     (None, 17, 17, 128)  0           batch_normalization_539[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_540 (Conv2D)             (None, 17, 17, 160)  143360      activation_539[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_540 (BatchN (None, 17, 17, 160)  480         conv2d_540[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_540 (Activation)     (None, 17, 17, 160)  0           batch_normalization_540[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_538 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_541 (Conv2D)             (None, 17, 17, 192)  215040      activation_540[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_538 (BatchN (None, 17, 17, 192)  576         conv2d_538[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_541 (BatchN (None, 17, 17, 192)  576         conv2d_541[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_538 (Activation)     (None, 17, 17, 192)  0           batch_normalization_538[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_541 (Activation)     (None, 17, 17, 192)  0           batch_normalization_541[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_538[0][0]             \n",
            "                                                                 activation_541[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_543 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_543 (BatchN (None, 17, 17, 128)  384         conv2d_543[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_543 (Activation)     (None, 17, 17, 128)  0           batch_normalization_543[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_544 (Conv2D)             (None, 17, 17, 160)  143360      activation_543[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_544 (BatchN (None, 17, 17, 160)  480         conv2d_544[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_544 (Activation)     (None, 17, 17, 160)  0           batch_normalization_544[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_542 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_545 (Conv2D)             (None, 17, 17, 192)  215040      activation_544[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_542 (BatchN (None, 17, 17, 192)  576         conv2d_542[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_545 (BatchN (None, 17, 17, 192)  576         conv2d_545[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_542 (Activation)     (None, 17, 17, 192)  0           batch_normalization_542[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_545 (Activation)     (None, 17, 17, 192)  0           batch_normalization_545[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_542[0][0]             \n",
            "                                                                 activation_545[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_547 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_547 (BatchN (None, 17, 17, 128)  384         conv2d_547[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_547 (Activation)     (None, 17, 17, 128)  0           batch_normalization_547[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_548 (Conv2D)             (None, 17, 17, 160)  143360      activation_547[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_548 (BatchN (None, 17, 17, 160)  480         conv2d_548[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_548 (Activation)     (None, 17, 17, 160)  0           batch_normalization_548[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_546 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_549 (Conv2D)             (None, 17, 17, 192)  215040      activation_548[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_546 (BatchN (None, 17, 17, 192)  576         conv2d_546[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_549 (BatchN (None, 17, 17, 192)  576         conv2d_549[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_546 (Activation)     (None, 17, 17, 192)  0           batch_normalization_546[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_549 (Activation)     (None, 17, 17, 192)  0           batch_normalization_549[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_546[0][0]             \n",
            "                                                                 activation_549[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_551 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_551 (BatchN (None, 17, 17, 128)  384         conv2d_551[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_551 (Activation)     (None, 17, 17, 128)  0           batch_normalization_551[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_552 (Conv2D)             (None, 17, 17, 160)  143360      activation_551[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_552 (BatchN (None, 17, 17, 160)  480         conv2d_552[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_552 (Activation)     (None, 17, 17, 160)  0           batch_normalization_552[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_550 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_553 (Conv2D)             (None, 17, 17, 192)  215040      activation_552[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_550 (BatchN (None, 17, 17, 192)  576         conv2d_550[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_553 (BatchN (None, 17, 17, 192)  576         conv2d_553[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_550 (Activation)     (None, 17, 17, 192)  0           batch_normalization_550[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_553 (Activation)     (None, 17, 17, 192)  0           batch_normalization_553[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_550[0][0]             \n",
            "                                                                 activation_553[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_555 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_555 (BatchN (None, 17, 17, 128)  384         conv2d_555[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_555 (Activation)     (None, 17, 17, 128)  0           batch_normalization_555[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_556 (Conv2D)             (None, 17, 17, 160)  143360      activation_555[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_556 (BatchN (None, 17, 17, 160)  480         conv2d_556[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_556 (Activation)     (None, 17, 17, 160)  0           batch_normalization_556[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_554 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_557 (Conv2D)             (None, 17, 17, 192)  215040      activation_556[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_554 (BatchN (None, 17, 17, 192)  576         conv2d_554[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_557 (BatchN (None, 17, 17, 192)  576         conv2d_557[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_554 (Activation)     (None, 17, 17, 192)  0           batch_normalization_554[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_557 (Activation)     (None, 17, 17, 192)  0           batch_normalization_557[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_554[0][0]             \n",
            "                                                                 activation_557[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_559 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_559 (BatchN (None, 17, 17, 128)  384         conv2d_559[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_559 (Activation)     (None, 17, 17, 128)  0           batch_normalization_559[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_560 (Conv2D)             (None, 17, 17, 160)  143360      activation_559[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_560 (BatchN (None, 17, 17, 160)  480         conv2d_560[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_560 (Activation)     (None, 17, 17, 160)  0           batch_normalization_560[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_558 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_561 (Conv2D)             (None, 17, 17, 192)  215040      activation_560[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_558 (BatchN (None, 17, 17, 192)  576         conv2d_558[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_561 (BatchN (None, 17, 17, 192)  576         conv2d_561[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_558 (Activation)     (None, 17, 17, 192)  0           batch_normalization_558[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_561 (Activation)     (None, 17, 17, 192)  0           batch_normalization_561[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_558[0][0]             \n",
            "                                                                 activation_561[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_566 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_566 (BatchN (None, 17, 17, 256)  768         conv2d_566[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_566 (Activation)     (None, 17, 17, 256)  0           batch_normalization_566[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_562 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_564 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_567 (Conv2D)             (None, 17, 17, 288)  663552      activation_566[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_562 (BatchN (None, 17, 17, 256)  768         conv2d_562[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_564 (BatchN (None, 17, 17, 256)  768         conv2d_564[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_567 (BatchN (None, 17, 17, 288)  864         conv2d_567[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_562 (Activation)     (None, 17, 17, 256)  0           batch_normalization_562[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_564 (Activation)     (None, 17, 17, 256)  0           batch_normalization_564[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_567 (Activation)     (None, 17, 17, 288)  0           batch_normalization_567[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_563 (Conv2D)             (None, 8, 8, 384)    884736      activation_562[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_565 (Conv2D)             (None, 8, 8, 288)    663552      activation_564[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_568 (Conv2D)             (None, 8, 8, 320)    829440      activation_567[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_563 (BatchN (None, 8, 8, 384)    1152        conv2d_563[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_565 (BatchN (None, 8, 8, 288)    864         conv2d_565[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_568 (BatchN (None, 8, 8, 320)    960         conv2d_568[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_563 (Activation)     (None, 8, 8, 384)    0           batch_normalization_563[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_565 (Activation)     (None, 8, 8, 288)    0           batch_normalization_565[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_568 (Activation)     (None, 8, 8, 320)    0           batch_normalization_568[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_563[0][0]             \n",
            "                                                                 activation_565[0][0]             \n",
            "                                                                 activation_568[0][0]             \n",
            "                                                                 max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_570 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_570 (BatchN (None, 8, 8, 192)    576         conv2d_570[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_570 (Activation)     (None, 8, 8, 192)    0           batch_normalization_570[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_571 (Conv2D)             (None, 8, 8, 224)    129024      activation_570[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_571 (BatchN (None, 8, 8, 224)    672         conv2d_571[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_571 (Activation)     (None, 8, 8, 224)    0           batch_normalization_571[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_569 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_572 (Conv2D)             (None, 8, 8, 256)    172032      activation_571[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_569 (BatchN (None, 8, 8, 192)    576         conv2d_569[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_572 (BatchN (None, 8, 8, 256)    768         conv2d_572[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_569 (Activation)     (None, 8, 8, 192)    0           batch_normalization_569[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_572 (Activation)     (None, 8, 8, 256)    0           batch_normalization_572[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_569[0][0]             \n",
            "                                                                 activation_572[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_574 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_574 (BatchN (None, 8, 8, 192)    576         conv2d_574[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_574 (Activation)     (None, 8, 8, 192)    0           batch_normalization_574[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_575 (Conv2D)             (None, 8, 8, 224)    129024      activation_574[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_575 (BatchN (None, 8, 8, 224)    672         conv2d_575[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_575 (Activation)     (None, 8, 8, 224)    0           batch_normalization_575[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_573 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_576 (Conv2D)             (None, 8, 8, 256)    172032      activation_575[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_573 (BatchN (None, 8, 8, 192)    576         conv2d_573[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_576 (BatchN (None, 8, 8, 256)    768         conv2d_576[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_573 (Activation)     (None, 8, 8, 192)    0           batch_normalization_573[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_576 (Activation)     (None, 8, 8, 256)    0           batch_normalization_576[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_573[0][0]             \n",
            "                                                                 activation_576[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_578 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_578 (BatchN (None, 8, 8, 192)    576         conv2d_578[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_578 (Activation)     (None, 8, 8, 192)    0           batch_normalization_578[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_579 (Conv2D)             (None, 8, 8, 224)    129024      activation_578[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_579 (BatchN (None, 8, 8, 224)    672         conv2d_579[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_579 (Activation)     (None, 8, 8, 224)    0           batch_normalization_579[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_577 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_580 (Conv2D)             (None, 8, 8, 256)    172032      activation_579[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_577 (BatchN (None, 8, 8, 192)    576         conv2d_577[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_580 (BatchN (None, 8, 8, 256)    768         conv2d_580[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_577 (Activation)     (None, 8, 8, 192)    0           batch_normalization_577[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_580 (Activation)     (None, 8, 8, 256)    0           batch_normalization_580[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_577[0][0]             \n",
            "                                                                 activation_580[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_582 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_582 (BatchN (None, 8, 8, 192)    576         conv2d_582[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_582 (Activation)     (None, 8, 8, 192)    0           batch_normalization_582[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_583 (Conv2D)             (None, 8, 8, 224)    129024      activation_582[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_583 (BatchN (None, 8, 8, 224)    672         conv2d_583[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_583 (Activation)     (None, 8, 8, 224)    0           batch_normalization_583[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_581 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_584 (Conv2D)             (None, 8, 8, 256)    172032      activation_583[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_581 (BatchN (None, 8, 8, 192)    576         conv2d_581[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_584 (BatchN (None, 8, 8, 256)    768         conv2d_584[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_581 (Activation)     (None, 8, 8, 192)    0           batch_normalization_581[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_584 (Activation)     (None, 8, 8, 256)    0           batch_normalization_584[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_581[0][0]             \n",
            "                                                                 activation_584[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_586 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_586 (BatchN (None, 8, 8, 192)    576         conv2d_586[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_586 (Activation)     (None, 8, 8, 192)    0           batch_normalization_586[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_587 (Conv2D)             (None, 8, 8, 224)    129024      activation_586[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_587 (BatchN (None, 8, 8, 224)    672         conv2d_587[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_587 (Activation)     (None, 8, 8, 224)    0           batch_normalization_587[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_585 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_588 (Conv2D)             (None, 8, 8, 256)    172032      activation_587[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_585 (BatchN (None, 8, 8, 192)    576         conv2d_585[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_588 (BatchN (None, 8, 8, 256)    768         conv2d_588[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_585 (Activation)     (None, 8, 8, 192)    0           batch_normalization_585[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_588 (Activation)     (None, 8, 8, 256)    0           batch_normalization_588[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_585[0][0]             \n",
            "                                                                 activation_588[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_590 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_590 (BatchN (None, 8, 8, 192)    576         conv2d_590[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_590 (Activation)     (None, 8, 8, 192)    0           batch_normalization_590[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_591 (Conv2D)             (None, 8, 8, 224)    129024      activation_590[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_591 (BatchN (None, 8, 8, 224)    672         conv2d_591[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_591 (Activation)     (None, 8, 8, 224)    0           batch_normalization_591[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_589 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_592 (Conv2D)             (None, 8, 8, 256)    172032      activation_591[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_589 (BatchN (None, 8, 8, 192)    576         conv2d_589[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_592 (BatchN (None, 8, 8, 256)    768         conv2d_592[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_589 (Activation)     (None, 8, 8, 192)    0           batch_normalization_589[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_592 (Activation)     (None, 8, 8, 256)    0           batch_normalization_592[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_589[0][0]             \n",
            "                                                                 activation_592[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_594 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_594 (BatchN (None, 8, 8, 192)    576         conv2d_594[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_594 (Activation)     (None, 8, 8, 192)    0           batch_normalization_594[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_595 (Conv2D)             (None, 8, 8, 224)    129024      activation_594[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_595 (BatchN (None, 8, 8, 224)    672         conv2d_595[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_595 (Activation)     (None, 8, 8, 224)    0           batch_normalization_595[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_593 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_596 (Conv2D)             (None, 8, 8, 256)    172032      activation_595[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_593 (BatchN (None, 8, 8, 192)    576         conv2d_593[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_596 (BatchN (None, 8, 8, 256)    768         conv2d_596[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_593 (Activation)     (None, 8, 8, 192)    0           batch_normalization_593[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_596 (Activation)     (None, 8, 8, 256)    0           batch_normalization_596[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_593[0][0]             \n",
            "                                                                 activation_596[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_598 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_598 (BatchN (None, 8, 8, 192)    576         conv2d_598[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_598 (Activation)     (None, 8, 8, 192)    0           batch_normalization_598[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_599 (Conv2D)             (None, 8, 8, 224)    129024      activation_598[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_599 (BatchN (None, 8, 8, 224)    672         conv2d_599[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_599 (Activation)     (None, 8, 8, 224)    0           batch_normalization_599[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_597 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_600 (Conv2D)             (None, 8, 8, 256)    172032      activation_599[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_597 (BatchN (None, 8, 8, 192)    576         conv2d_597[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_600 (BatchN (None, 8, 8, 256)    768         conv2d_600[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_597 (Activation)     (None, 8, 8, 192)    0           batch_normalization_597[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_600 (Activation)     (None, 8, 8, 256)    0           batch_normalization_600[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_597[0][0]             \n",
            "                                                                 activation_600[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_602 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_602 (BatchN (None, 8, 8, 192)    576         conv2d_602[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_602 (Activation)     (None, 8, 8, 192)    0           batch_normalization_602[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_603 (Conv2D)             (None, 8, 8, 224)    129024      activation_602[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_603 (BatchN (None, 8, 8, 224)    672         conv2d_603[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_603 (Activation)     (None, 8, 8, 224)    0           batch_normalization_603[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_601 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_604 (Conv2D)             (None, 8, 8, 256)    172032      activation_603[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_601 (BatchN (None, 8, 8, 192)    576         conv2d_601[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_604 (BatchN (None, 8, 8, 256)    768         conv2d_604[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_601 (Activation)     (None, 8, 8, 192)    0           batch_normalization_601[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_604 (Activation)     (None, 8, 8, 256)    0           batch_normalization_604[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_601[0][0]             \n",
            "                                                                 activation_604[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_606 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_606 (BatchN (None, 8, 8, 192)    576         conv2d_606[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_606 (Activation)     (None, 8, 8, 192)    0           batch_normalization_606[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_607 (Conv2D)             (None, 8, 8, 224)    129024      activation_606[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_607 (BatchN (None, 8, 8, 224)    672         conv2d_607[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_607 (Activation)     (None, 8, 8, 224)    0           batch_normalization_607[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_605 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_608 (Conv2D)             (None, 8, 8, 256)    172032      activation_607[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_605 (BatchN (None, 8, 8, 192)    576         conv2d_605[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_608 (BatchN (None, 8, 8, 256)    768         conv2d_608[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_605 (Activation)     (None, 8, 8, 192)    0           batch_normalization_605[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_608 (Activation)     (None, 8, 8, 256)    0           batch_normalization_608[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_605[0][0]             \n",
            "                                                                 activation_608[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 8, 8, 1536)   3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 8, 8, 1536)   4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 8, 8, 1536)   0           conv_7b_bn[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 54,336,736\n",
            "Trainable params: 54,276,192\n",
            "Non-trainable params: 60,544\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qruO9BBXiLja"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kboc7kjc4wke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "d3f028fe-6a43-49ec-d0d1-5c1dd732fee4"
      },
      "source": [
        "learning_rates = [0.001,0.0003,0.0001,0.00003,0.00001,0.000003,0.000001]\n",
        "for lr in learning_rates:\n",
        "  model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "  history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=6, steps_per_epoch=20, validation_steps=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "20/20 [==============================] - 91s 5s/step - loss: 3.8179 - categorical_accuracy: 0.4945 - val_loss: 3.3714 - val_categorical_accuracy: 0.6322\n",
            "Epoch 2/6\n",
            "20/20 [==============================] - 94s 5s/step - loss: 2.6773 - categorical_accuracy: 0.6855 - val_loss: 2.9659 - val_categorical_accuracy: 0.6656\n",
            "Epoch 3/6\n",
            "20/20 [==============================] - 95s 5s/step - loss: 2.1915 - categorical_accuracy: 0.7176 - val_loss: 2.4433 - val_categorical_accuracy: 0.6949\n",
            "Epoch 4/6\n",
            "20/20 [==============================] - 94s 5s/step - loss: 1.9128 - categorical_accuracy: 0.7402 - val_loss: 2.5042 - val_categorical_accuracy: 0.6832\n",
            "Epoch 5/6\n",
            "20/20 [==============================] - 96s 5s/step - loss: 1.7495 - categorical_accuracy: 0.7613 - val_loss: 2.3186 - val_categorical_accuracy: 0.6895\n",
            "Epoch 6/6\n",
            "20/20 [==============================] - 96s 5s/step - loss: 1.6751 - categorical_accuracy: 0.7668 - val_loss: 2.4008 - val_categorical_accuracy: 0.6633\n",
            "Epoch 1/6\n",
            "20/20 [==============================] - 94s 5s/step - loss: 1.4536 - categorical_accuracy: 0.7844 - val_loss: 2.0772 - val_categorical_accuracy: 0.7180\n",
            "Epoch 2/6\n",
            "20/20 [==============================] - 93s 5s/step - loss: 1.3068 - categorical_accuracy: 0.7910 - val_loss: 1.8953 - val_categorical_accuracy: 0.7168\n",
            "Epoch 3/6\n",
            "20/20 [==============================] - 90s 5s/step - loss: 1.1947 - categorical_accuracy: 0.8180 - val_loss: 1.8956 - val_categorical_accuracy: 0.7089\n",
            "Epoch 4/6\n",
            "20/20 [==============================] - 96s 5s/step - loss: 1.1194 - categorical_accuracy: 0.8277 - val_loss: 1.8973 - val_categorical_accuracy: 0.7164\n",
            "Epoch 5/6\n",
            "20/20 [==============================] - 96s 5s/step - loss: 1.1112 - categorical_accuracy: 0.8137 - val_loss: 1.9502 - val_categorical_accuracy: 0.7082\n",
            "Epoch 6/6\n",
            "20/20 [==============================] - 93s 5s/step - loss: 1.0341 - categorical_accuracy: 0.8348 - val_loss: 1.8659 - val_categorical_accuracy: 0.7129\n",
            "Epoch 1/6\n",
            "20/20 [==============================] - 94s 5s/step - loss: 0.9896 - categorical_accuracy: 0.8406 - val_loss: 1.7632 - val_categorical_accuracy: 0.7332\n",
            "Epoch 2/6\n",
            "20/20 [==============================] - 98s 5s/step - loss: 0.9617 - categorical_accuracy: 0.8379 - val_loss: 1.8228 - val_categorical_accuracy: 0.7211\n",
            "Epoch 3/6\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.9446 - categorical_accuracy: 0.8414 - val_loss: 1.8417 - val_categorical_accuracy: 0.7156\n",
            "Epoch 4/6\n",
            " 9/20 [============>.................] - ETA: 20s - loss: 0.9190 - categorical_accuracy: 0.8377"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-ce5cbeae3b9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    850\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbRfi5UYBwa-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "8d7aeb29-022c-40cb-a197-529e9d7e9f3c"
      },
      "source": [
        "\n",
        "model_fine = tf.keras.models.Sequential()\n",
        "\n",
        "model_fine.add(pre_model)\n",
        "model_fine.add(tf.keras.layers.LayerNormalization(axis=1 , center=True , scale=True))\n",
        "model_fine.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model_fine.add(tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=l2(0.01)))\n",
        "model_fine.add(tf.keras.layers.Dropout(0.4))\n",
        "model_fine.add(tf.keras.layers.Dense(32, activation='relu',kernel_regularizer=l2(0.01)))\n",
        "model_fine.add(tf.keras.layers.Dropout(0.3))\n",
        "model_fine.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
        "\n",
        "model_fine.summary()\n",
        "#pre_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "layer_normalization_5 (Layer (None, 7, 7, 512)         14        \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 12)                396       \n",
            "=================================================================\n",
            "Total params: 23,240,314\n",
            "Trainable params: 7,935,546\n",
            "Non-trainable params: 15,304,768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OD0F2E0CgdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10b3509f-bdd1-460a-b220-2c3c160bce79"
      },
      "source": [
        "learning_rates = [0.001,0.0003,0.0001,0.00003,0.00001,0.000003,0.000001]\n",
        "for lr in learning_rates:\n",
        "  model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "  history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=5, steps_per_epoch=20, validation_steps=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 95s 5s/step - loss: 5.4854 - categorical_accuracy: 0.5238 - val_loss: 4.4034 - val_categorical_accuracy: 0.7055\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 93s 5s/step - loss: 3.6170 - categorical_accuracy: 0.6871 - val_loss: 3.5548 - val_categorical_accuracy: 0.6898\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 92s 5s/step - loss: 2.7057 - categorical_accuracy: 0.7410 - val_loss: 2.8967 - val_categorical_accuracy: 0.7021\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 95s 5s/step - loss: 2.2270 - categorical_accuracy: 0.7676 - val_loss: 2.6882 - val_categorical_accuracy: 0.6938\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 97s 5s/step - loss: 1.9125 - categorical_accuracy: 0.7949 - val_loss: 2.5586 - val_categorical_accuracy: 0.6785\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 93s 5s/step - loss: 1.6557 - categorical_accuracy: 0.7973 - val_loss: 2.3537 - val_categorical_accuracy: 0.7063\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 93s 5s/step - loss: 1.4779 - categorical_accuracy: 0.8171 - val_loss: 2.1718 - val_categorical_accuracy: 0.7017\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 92s 5s/step - loss: 1.3818 - categorical_accuracy: 0.8207 - val_loss: 2.0863 - val_categorical_accuracy: 0.7188\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 91s 5s/step - loss: 1.2902 - categorical_accuracy: 0.8242 - val_loss: 1.9966 - val_categorical_accuracy: 0.7254\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 92s 5s/step - loss: 1.2269 - categorical_accuracy: 0.8434 - val_loss: 2.0274 - val_categorical_accuracy: 0.7090\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 89s 4s/step - loss: 1.1617 - categorical_accuracy: 0.8371 - val_loss: 1.9124 - val_categorical_accuracy: 0.7182\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 94s 5s/step - loss: 1.1114 - categorical_accuracy: 0.8516 - val_loss: 1.9506 - val_categorical_accuracy: 0.7195\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 92s 5s/step - loss: 1.1151 - categorical_accuracy: 0.8383 - val_loss: 1.8218 - val_categorical_accuracy: 0.7254\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 97s 5s/step - loss: 1.0709 - categorical_accuracy: 0.8473 - val_loss: 1.9798 - val_categorical_accuracy: 0.7105\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 92s 5s/step - loss: 1.0828 - categorical_accuracy: 0.8340 - val_loss: 1.8390 - val_categorical_accuracy: 0.7303\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 98s 5s/step - loss: 0.9880 - categorical_accuracy: 0.8648 - val_loss: 1.8645 - val_categorical_accuracy: 0.7289\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 93s 5s/step - loss: 1.0170 - categorical_accuracy: 0.8523 - val_loss: 1.9001 - val_categorical_accuracy: 0.7215\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 95s 5s/step - loss: 0.9909 - categorical_accuracy: 0.8609 - val_loss: 1.8030 - val_categorical_accuracy: 0.7266\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 91s 5s/step - loss: 0.9583 - categorical_accuracy: 0.8617 - val_loss: 1.9619 - val_categorical_accuracy: 0.7105\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 92s 5s/step - loss: 0.9591 - categorical_accuracy: 0.8578 - val_loss: 1.7917 - val_categorical_accuracy: 0.7430\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 94s 5s/step - loss: 0.9525 - categorical_accuracy: 0.8652 - val_loss: 1.8091 - val_categorical_accuracy: 0.7398\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 99s 5s/step - loss: 0.9662 - categorical_accuracy: 0.8535 - val_loss: 1.9322 - val_categorical_accuracy: 0.7043\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 94s 5s/step - loss: 0.9502 - categorical_accuracy: 0.8645 - val_loss: 1.8482 - val_categorical_accuracy: 0.7263\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.9537 - categorical_accuracy: 0.8586 - val_loss: 1.8299 - val_categorical_accuracy: 0.7352\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 94s 5s/step - loss: 0.9824 - categorical_accuracy: 0.8512 - val_loss: 1.7482 - val_categorical_accuracy: 0.7273\n",
            "Epoch 1/5\n",
            "20/20 [==============================] - 96s 5s/step - loss: 0.9706 - categorical_accuracy: 0.8516 - val_loss: 1.9355 - val_categorical_accuracy: 0.7160\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 97s 5s/step - loss: 0.9381 - categorical_accuracy: 0.8590 - val_loss: 1.8341 - val_categorical_accuracy: 0.7207\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.9649 - categorical_accuracy: 0.8562"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5445fed0f7be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    876\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                 step_num=step):\n\u001b[1;32m   1083\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ30AiCeWsoS"
      },
      "source": [
        "for layer in pre_model.layers[:-2]:\n",
        "    layer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8mtVJ0Eqotl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "afe02e8d-d90e-41b3-b8ca-0febcb4505e1"
      },
      "source": [
        "\n",
        "model_fine = tf.keras.models.Sequential()\n",
        "\n",
        "model_fine.add(pre_model)\n",
        "model_fine.add(tf.keras.layers.LayerNormalization(axis=1 , center=True , scale=True))\n",
        "model_fine.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model_fine.add(tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=l2(0.01)\n",
        "))\n",
        "#model_fine.add(tf.keras.layers.Dropout(0.2))\n",
        "model_fine.add(tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=l2(0.01)\n",
        "))\n",
        "#model_fine.add(tf.keras.layers.Dropout(0.2))\n",
        "model_fine.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
        "\n",
        "model_fine.summary()\n",
        "#pre_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Model)  (None, 5, 5, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "layer_normalization_1 (Layer (None, 5, 5, 1536)        10        \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 38400)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                2457664   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 12)                780       \n",
            "=================================================================\n",
            "Total params: 56,799,350\n",
            "Trainable params: 6,592,950\n",
            "Non-trainable params: 50,206,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLoO4V3Udl9l"
      },
      "source": [
        "bb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv6lxeh_p6ne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b24417e7-50c6-4f71-fd05-be5757b0b9c4"
      },
      "source": [
        "#learning_rates = [0.003,0.001,0.0003,0.0001,0.00003,0.00001,0.000003,0.000001]\n",
        "#for lr in learning_rates:\n",
        "model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=50, steps_per_epoch=20, validation_steps=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 77s 4s/step - loss: 4.7864 - categorical_accuracy: 0.1730 - val_loss: 4.6147 - val_categorical_accuracy: 0.2227\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 4.3323 - categorical_accuracy: 0.2496 - val_loss: 4.1092 - val_categorical_accuracy: 0.2934\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 3.7739 - categorical_accuracy: 0.3539 - val_loss: 3.7311 - val_categorical_accuracy: 0.3418\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 69s 3s/step - loss: 3.2963 - categorical_accuracy: 0.4035 - val_loss: 3.4026 - val_categorical_accuracy: 0.3443\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 77s 4s/step - loss: 2.9346 - categorical_accuracy: 0.4512 - val_loss: 3.1498 - val_categorical_accuracy: 0.4422\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 78s 4s/step - loss: 2.7364 - categorical_accuracy: 0.4715 - val_loss: 2.8742 - val_categorical_accuracy: 0.4414\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 2.5678 - categorical_accuracy: 0.5035 - val_loss: 2.8493 - val_categorical_accuracy: 0.4605\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 74s 4s/step - loss: 2.4081 - categorical_accuracy: 0.5305 - val_loss: 2.6721 - val_categorical_accuracy: 0.4758\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 2.3385 - categorical_accuracy: 0.5270 - val_loss: 2.6522 - val_categorical_accuracy: 0.4738\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 2.2457 - categorical_accuracy: 0.5605 - val_loss: 2.5184 - val_categorical_accuracy: 0.5156\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 79s 4s/step - loss: 2.0829 - categorical_accuracy: 0.5926 - val_loss: 2.4398 - val_categorical_accuracy: 0.5262\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 2.0172 - categorical_accuracy: 0.6059 - val_loss: 2.5273 - val_categorical_accuracy: 0.5188\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 2.0386 - categorical_accuracy: 0.5852 - val_loss: 2.3726 - val_categorical_accuracy: 0.5221\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 76s 4s/step - loss: 2.0055 - categorical_accuracy: 0.5777 - val_loss: 2.3168 - val_categorical_accuracy: 0.5426\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 77s 4s/step - loss: 1.9219 - categorical_accuracy: 0.6270 - val_loss: 2.4686 - val_categorical_accuracy: 0.5348\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 77s 4s/step - loss: 1.8189 - categorical_accuracy: 0.6266 - val_loss: 2.2169 - val_categorical_accuracy: 0.5777\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 79s 4s/step - loss: 1.7996 - categorical_accuracy: 0.6344 - val_loss: 2.2741 - val_categorical_accuracy: 0.5371\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 74s 4s/step - loss: 1.7827 - categorical_accuracy: 0.6242 - val_loss: 2.1800 - val_categorical_accuracy: 0.5611\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 76s 4s/step - loss: 1.6960 - categorical_accuracy: 0.6465 - val_loss: 2.2379 - val_categorical_accuracy: 0.5648\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.6603 - categorical_accuracy: 0.6578 - val_loss: 2.1202 - val_categorical_accuracy: 0.5625\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 1.6480 - categorical_accuracy: 0.6465 - val_loss: 1.9885 - val_categorical_accuracy: 0.5875\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.6085 - categorical_accuracy: 0.6633 - val_loss: 1.9885 - val_categorical_accuracy: 0.5867\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 72s 4s/step - loss: 1.5321 - categorical_accuracy: 0.6715 - val_loss: 2.1148 - val_categorical_accuracy: 0.5541\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 79s 4s/step - loss: 1.5777 - categorical_accuracy: 0.6570 - val_loss: 2.0096 - val_categorical_accuracy: 0.5898\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.5184 - categorical_accuracy: 0.6797 - val_loss: 2.0054 - val_categorical_accuracy: 0.5949\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 76s 4s/step - loss: 1.5044 - categorical_accuracy: 0.6645 - val_loss: 1.9153 - val_categorical_accuracy: 0.5875\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 76s 4s/step - loss: 1.4931 - categorical_accuracy: 0.6805 - val_loss: 1.9306 - val_categorical_accuracy: 0.5902\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 74s 4s/step - loss: 1.4761 - categorical_accuracy: 0.6871 - val_loss: 1.9745 - val_categorical_accuracy: 0.6012\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 79s 4s/step - loss: 1.4445 - categorical_accuracy: 0.6848 - val_loss: 1.8655 - val_categorical_accuracy: 0.5992\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 77s 4s/step - loss: 1.3774 - categorical_accuracy: 0.7063 - val_loss: 1.9123 - val_categorical_accuracy: 0.6148\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 77s 4s/step - loss: 1.4086 - categorical_accuracy: 0.6980 - val_loss: 2.0008 - val_categorical_accuracy: 0.5801\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 76s 4s/step - loss: 1.4077 - categorical_accuracy: 0.6953 - val_loss: 1.8817 - val_categorical_accuracy: 0.6098\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 79s 4s/step - loss: 1.4005 - categorical_accuracy: 0.6875 - val_loss: 1.8410 - val_categorical_accuracy: 0.5988\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 72s 4s/step - loss: 1.3950 - categorical_accuracy: 0.6977 - val_loss: 2.0022 - val_categorical_accuracy: 0.5957\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 74s 4s/step - loss: 1.3662 - categorical_accuracy: 0.6973 - val_loss: 2.1374 - val_categorical_accuracy: 0.5535\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 77s 4s/step - loss: 1.4789 - categorical_accuracy: 0.6727 - val_loss: 1.9933 - val_categorical_accuracy: 0.5934\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 76s 4s/step - loss: 1.4093 - categorical_accuracy: 0.6969 - val_loss: 1.8804 - val_categorical_accuracy: 0.6164\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 73s 4s/step - loss: 1.3414 - categorical_accuracy: 0.7098 - val_loss: 1.7996 - val_categorical_accuracy: 0.6266\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 1.3233 - categorical_accuracy: 0.7125 - val_loss: 1.8049 - val_categorical_accuracy: 0.6281\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 73s 4s/step - loss: 1.3023 - categorical_accuracy: 0.7105 - val_loss: 1.8363 - val_categorical_accuracy: 0.6113\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 72s 4s/step - loss: 1.3040 - categorical_accuracy: 0.7094 - val_loss: 1.7835 - val_categorical_accuracy: 0.6086\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 74s 4s/step - loss: 1.2636 - categorical_accuracy: 0.7262 - val_loss: 1.7605 - val_categorical_accuracy: 0.6275\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 77s 4s/step - loss: 1.2640 - categorical_accuracy: 0.7254 - val_loss: 1.7914 - val_categorical_accuracy: 0.6203\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 75s 4s/step - loss: 1.2533 - categorical_accuracy: 0.7195 - val_loss: 1.7573 - val_categorical_accuracy: 0.6219\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 73s 4s/step - loss: 1.2605 - categorical_accuracy: 0.7250 - val_loss: 1.7504 - val_categorical_accuracy: 0.6242\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 72s 4s/step - loss: 1.2435 - categorical_accuracy: 0.7250 - val_loss: 1.7323 - val_categorical_accuracy: 0.6367\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 74s 4s/step - loss: 1.2463 - categorical_accuracy: 0.7254 - val_loss: 1.6975 - val_categorical_accuracy: 0.6193\n",
            "Epoch 48/50\n",
            "13/20 [==================>...........] - ETA: 10s - loss: 1.2859 - categorical_accuracy: 0.7007"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ZHY8A8fTyD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "b0467a3f-7b4c-4faa-9087-de3c447f6b8d"
      },
      "source": [
        "\n",
        "model_fine = tf.keras.models.Sequential()\n",
        "\n",
        "model_fine.add(pre_model)\n",
        "model_fine.add(tf.keras.layers.LayerNormalization(axis=1 , center=True , scale=True))\n",
        "model_fine.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model_fine.add(tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=l2(0.01)))\n",
        "model_fine.add(tf.keras.layers.Dropout(0.2))\n",
        "#model_fine.add(tf.keras.layers.Dense(32, activation='relu',kernel_regularizer=l2(0.01)))\n",
        "#model_fine.add(tf.keras.layers.Dropout(0.2))\n",
        "model_fine.add(tf.keras.layers.Dense(12, activation='softmax'))\n",
        "\n",
        "model_fine.summary()\n",
        "#pre_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "layer_normalization_5 (Layer (None, 7, 7, 512)         14        \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                1605696   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 12)                780       \n",
            "=================================================================\n",
            "Total params: 16,321,178\n",
            "Trainable params: 3,966,298\n",
            "Non-trainable params: 12,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pu1X4FAfZLb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd497122-9e2e-48b2-ecfc-8d486807591b"
      },
      "source": [
        "learning_rates = [0.003,0.001,0.0003,0.0001,0.00003,0.00001,0.000003,0.000001,0.0000003]\n",
        "for lr in learning_rates:\n",
        "       model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "       history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=7, steps_per_epoch=20, validation_steps=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "20/20 [==============================] - 80s 4s/step - loss: 4.3046 - categorical_accuracy: 0.2914 - val_loss: 3.6882 - val_categorical_accuracy: 0.4152\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - 82s 4s/step - loss: 3.3213 - categorical_accuracy: 0.4473 - val_loss: 2.8861 - val_categorical_accuracy: 0.5348\n",
            "Epoch 3/7\n",
            "20/20 [==============================] - 77s 4s/step - loss: 2.6224 - categorical_accuracy: 0.5070 - val_loss: 2.4650 - val_categorical_accuracy: 0.5551\n",
            "Epoch 4/7\n",
            "20/20 [==============================] - 83s 4s/step - loss: 2.2427 - categorical_accuracy: 0.5617 - val_loss: 2.1711 - val_categorical_accuracy: 0.6066\n",
            "Epoch 5/7\n",
            "20/20 [==============================] - 80s 4s/step - loss: 2.0417 - categorical_accuracy: 0.5766 - val_loss: 2.1111 - val_categorical_accuracy: 0.6109\n",
            "Epoch 6/7\n",
            "20/20 [==============================] - 81s 4s/step - loss: 1.9389 - categorical_accuracy: 0.6082 - val_loss: 2.1253 - val_categorical_accuracy: 0.5871\n",
            "Epoch 7/7\n",
            "20/20 [==============================] - 83s 4s/step - loss: 1.9473 - categorical_accuracy: 0.5918 - val_loss: 2.0898 - val_categorical_accuracy: 0.5754\n",
            "Epoch 1/7\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.7217 - categorical_accuracy: 0.6222 - val_loss: 1.7965 - val_categorical_accuracy: 0.6375\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.5680 - categorical_accuracy: 0.6512 - val_loss: 1.7634 - val_categorical_accuracy: 0.6523\n",
            "Epoch 3/7\n",
            "20/20 [==============================] - 80s 4s/step - loss: 1.4679 - categorical_accuracy: 0.6758 - val_loss: 1.6919 - val_categorical_accuracy: 0.6656\n",
            "Epoch 4/7\n",
            "20/20 [==============================] - 79s 4s/step - loss: 1.4203 - categorical_accuracy: 0.6695 - val_loss: 1.5677 - val_categorical_accuracy: 0.6766\n",
            "Epoch 5/7\n",
            "20/20 [==============================] - 75s 4s/step - loss: 1.3622 - categorical_accuracy: 0.6766 - val_loss: 1.5268 - val_categorical_accuracy: 0.6672\n",
            "Epoch 6/7\n",
            "20/20 [==============================] - 81s 4s/step - loss: 1.2900 - categorical_accuracy: 0.7031 - val_loss: 1.5174 - val_categorical_accuracy: 0.6729\n",
            "Epoch 7/7\n",
            "20/20 [==============================] - 80s 4s/step - loss: 1.2899 - categorical_accuracy: 0.6742 - val_loss: 1.4855 - val_categorical_accuracy: 0.6777\n",
            "Epoch 1/7\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.1933 - categorical_accuracy: 0.6871 - val_loss: 1.4293 - val_categorical_accuracy: 0.7008\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - 79s 4s/step - loss: 1.1098 - categorical_accuracy: 0.7273 - val_loss: 1.3616 - val_categorical_accuracy: 0.7066\n",
            "Epoch 3/7\n",
            "20/20 [==============================] - 79s 4s/step - loss: 1.1150 - categorical_accuracy: 0.7137 - val_loss: 1.3536 - val_categorical_accuracy: 0.6996\n",
            "Epoch 4/7\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.0566 - categorical_accuracy: 0.7293 - val_loss: 1.3311 - val_categorical_accuracy: 0.7020\n",
            "Epoch 5/7\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.0413 - categorical_accuracy: 0.7465 - val_loss: 1.3711 - val_categorical_accuracy: 0.6918\n",
            "Epoch 6/7\n",
            "20/20 [==============================] - 76s 4s/step - loss: 1.0374 - categorical_accuracy: 0.7301 - val_loss: 1.4087 - val_categorical_accuracy: 0.6919\n",
            "Epoch 7/7\n",
            "20/20 [==============================] - 79s 4s/step - loss: 1.0315 - categorical_accuracy: 0.7359 - val_loss: 1.2830 - val_categorical_accuracy: 0.7168\n",
            "Epoch 1/7\n",
            "20/20 [==============================] - 79s 4s/step - loss: 0.9861 - categorical_accuracy: 0.7406 - val_loss: 1.3115 - val_categorical_accuracy: 0.7098\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - 77s 4s/step - loss: 0.9776 - categorical_accuracy: 0.7449 - val_loss: 1.2724 - val_categorical_accuracy: 0.7133\n",
            "Epoch 3/7\n",
            "20/20 [==============================] - 85s 4s/step - loss: 0.9643 - categorical_accuracy: 0.7551 - val_loss: 1.2793 - val_categorical_accuracy: 0.7258\n",
            "Epoch 4/7\n",
            "20/20 [==============================] - 79s 4s/step - loss: 0.9522 - categorical_accuracy: 0.7551 - val_loss: 1.2859 - val_categorical_accuracy: 0.7270\n",
            "Epoch 5/7\n",
            "20/20 [==============================] - 78s 4s/step - loss: 0.9499 - categorical_accuracy: 0.7402 - val_loss: 1.3113 - val_categorical_accuracy: 0.7063\n",
            "Epoch 6/7\n",
            "20/20 [==============================] - 79s 4s/step - loss: 0.9808 - categorical_accuracy: 0.7504 - val_loss: 1.1444 - val_categorical_accuracy: 0.7332\n",
            "Epoch 7/7\n",
            "20/20 [==============================] - 80s 4s/step - loss: 0.9473 - categorical_accuracy: 0.7613 - val_loss: 1.2799 - val_categorical_accuracy: 0.7133\n",
            "Epoch 1/7\n",
            "20/20 [==============================] - 78s 4s/step - loss: 0.9463 - categorical_accuracy: 0.7457 - val_loss: 1.2240 - val_categorical_accuracy: 0.7336\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - 77s 4s/step - loss: 0.9180 - categorical_accuracy: 0.7602 - val_loss: 1.2624 - val_categorical_accuracy: 0.7199\n",
            "Epoch 3/7\n",
            "20/20 [==============================] - 85s 4s/step - loss: 0.9252 - categorical_accuracy: 0.7641 - val_loss: 1.2483 - val_categorical_accuracy: 0.7172\n",
            "Epoch 4/7\n",
            "20/20 [==============================] - 81s 4s/step - loss: 0.8966 - categorical_accuracy: 0.7715 - val_loss: 1.2503 - val_categorical_accuracy: 0.7129\n",
            "Epoch 5/7\n",
            "20/20 [==============================] - 82s 4s/step - loss: 0.9350 - categorical_accuracy: 0.7402 - val_loss: 1.2989 - val_categorical_accuracy: 0.7281\n",
            "Epoch 6/7\n",
            "20/20 [==============================] - 79s 4s/step - loss: 0.9208 - categorical_accuracy: 0.7629 - val_loss: 1.2169 - val_categorical_accuracy: 0.7281\n",
            "Epoch 7/7\n",
            "20/20 [==============================] - 77s 4s/step - loss: 0.9026 - categorical_accuracy: 0.7664 - val_loss: 1.2177 - val_categorical_accuracy: 0.7250\n",
            "Epoch 1/7\n",
            "20/20 [==============================] - 82s 4s/step - loss: 0.9168 - categorical_accuracy: 0.7723 - val_loss: 1.1860 - val_categorical_accuracy: 0.7406\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.9414 - categorical_accuracy: 0.7520"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d85a2168c367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m        \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    810\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 step_num=step):\n\u001b[1;32m   1017\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3bwMMoy_u7A"
      },
      "source": [
        "for layer in pre_model.layers[:-4]:\n",
        "    layer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxW60DTK_0KX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8252de89-0ec7-404b-fcef-a2e3723eaf0f"
      },
      "source": [
        "learning_rates = [0.003,0.001,0.0003,0.0001,0.00003,0.00001,0.000003,0.000001]\n",
        "for lr in learning_rates:\n",
        "       model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "       history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=7, steps_per_epoch=20, validation_steps=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "20/20 [==============================] - 85s 4s/step - loss: 2.8096 - categorical_accuracy: 0.3113 - val_loss: 2.2366 - val_categorical_accuracy: 0.5277\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - 81s 4s/step - loss: 2.2490 - categorical_accuracy: 0.4734 - val_loss: 1.9622 - val_categorical_accuracy: 0.5980\n",
            "Epoch 3/7\n",
            "20/20 [==============================] - 86s 4s/step - loss: 2.0786 - categorical_accuracy: 0.5137 - val_loss: 2.0500 - val_categorical_accuracy: 0.5695\n",
            "Epoch 4/7\n",
            "20/20 [==============================] - 83s 4s/step - loss: 1.9842 - categorical_accuracy: 0.5367 - val_loss: 1.8835 - val_categorical_accuracy: 0.6191\n",
            "Epoch 5/7\n",
            "20/20 [==============================] - 84s 4s/step - loss: 1.8630 - categorical_accuracy: 0.5699 - val_loss: 1.8643 - val_categorical_accuracy: 0.6313\n",
            "Epoch 6/7\n",
            "20/20 [==============================] - 83s 4s/step - loss: 1.8532 - categorical_accuracy: 0.5805 - val_loss: 1.8268 - val_categorical_accuracy: 0.6380\n",
            "Epoch 7/7\n",
            "20/20 [==============================] - 85s 4s/step - loss: 1.8757 - categorical_accuracy: 0.5801 - val_loss: 1.7839 - val_categorical_accuracy: 0.6395\n",
            "Epoch 1/7\n",
            "20/20 [==============================] - 83s 4s/step - loss: 1.6779 - categorical_accuracy: 0.5844 - val_loss: 1.6312 - val_categorical_accuracy: 0.6668\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - 85s 4s/step - loss: 1.5379 - categorical_accuracy: 0.6395 - val_loss: 1.6243 - val_categorical_accuracy: 0.6406\n",
            "Epoch 3/7\n",
            "20/20 [==============================] - 82s 4s/step - loss: 1.4359 - categorical_accuracy: 0.6523 - val_loss: 1.5279 - val_categorical_accuracy: 0.6750\n",
            "Epoch 4/7\n",
            "20/20 [==============================] - 83s 4s/step - loss: 1.3984 - categorical_accuracy: 0.6457 - val_loss: 1.4507 - val_categorical_accuracy: 0.6883\n",
            "Epoch 5/7\n",
            "20/20 [==============================] - 78s 4s/step - loss: 1.3253 - categorical_accuracy: 0.6617 - val_loss: 1.4521 - val_categorical_accuracy: 0.6801\n",
            "Epoch 6/7\n",
            "20/20 [==============================] - 83s 4s/step - loss: 1.2663 - categorical_accuracy: 0.6758 - val_loss: 1.3969 - val_categorical_accuracy: 0.6880\n",
            "Epoch 7/7\n",
            "20/20 [==============================] - 85s 4s/step - loss: 1.2892 - categorical_accuracy: 0.6703 - val_loss: 1.4254 - val_categorical_accuracy: 0.6855\n",
            "Epoch 1/7\n",
            "20/20 [==============================] - 81s 4s/step - loss: 1.2406 - categorical_accuracy: 0.6660 - val_loss: 1.4064 - val_categorical_accuracy: 0.6879\n",
            "Epoch 2/7\n",
            "20/20 [==============================] - 86s 4s/step - loss: 1.1998 - categorical_accuracy: 0.6859 - val_loss: 1.3381 - val_categorical_accuracy: 0.6891\n",
            "Epoch 3/7\n",
            "20/20 [==============================] - 85s 4s/step - loss: 1.1953 - categorical_accuracy: 0.6777 - val_loss: 1.3245 - val_categorical_accuracy: 0.7051\n",
            "Epoch 4/7\n",
            "20/20 [==============================] - 83s 4s/step - loss: 1.1385 - categorical_accuracy: 0.6934 - val_loss: 1.3215 - val_categorical_accuracy: 0.6988\n",
            "Epoch 5/7\n",
            "20/20 [==============================] - 82s 4s/step - loss: 1.1331 - categorical_accuracy: 0.7016 - val_loss: 1.2680 - val_categorical_accuracy: 0.7023\n",
            "Epoch 6/7\n",
            "20/20 [==============================] - 86s 4s/step - loss: 1.1055 - categorical_accuracy: 0.6953 - val_loss: 1.2403 - val_categorical_accuracy: 0.7170\n",
            "Epoch 7/7\n",
            "15/20 [=====================>........] - ETA: 10s - loss: 1.0997 - categorical_accuracy: 0.6990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-838dd12a049b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m        \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzCSSCjKQy3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f80b7fab-cf4d-4f29-f544-57e500086364"
      },
      "source": [
        "model_fine.save(\"drive/My Drive/GHARBcurr_2.h5\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytOfVVHxfxe0"
      },
      "source": [
        "model_fine.evaluate_generator(val_data_gen)\n",
        "\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(20)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVGl7H0ccGp_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "5181c8f7-3ddd-44b3-eaba-c8eacd3c5081"
      },
      "source": [
        "model_fine.compile(optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.00005), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "\n",
        "history = model_fine.fit_generator(train_data_gen, validation_data=val_data_gen, epochs=20, steps_per_epoch=20, validation_steps=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 69s 3s/step - loss: 2.1159 - categorical_accuracy: 0.4648 - val_loss: 1.8783 - val_categorical_accuracy: 0.5773\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 68s 3s/step - loss: 2.0288 - categorical_accuracy: 0.4867 - val_loss: 1.8474 - val_categorical_accuracy: 0.5844\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 68s 3s/step - loss: 1.9135 - categorical_accuracy: 0.5117 - val_loss: 1.8193 - val_categorical_accuracy: 0.5902\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 65s 3s/step - loss: 1.8945 - categorical_accuracy: 0.5141 - val_loss: 1.7240 - val_categorical_accuracy: 0.6039\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 68s 3s/step - loss: 1.8430 - categorical_accuracy: 0.5383 - val_loss: 1.7429 - val_categorical_accuracy: 0.6164\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 70s 3s/step - loss: 1.8217 - categorical_accuracy: 0.5344 - val_loss: 1.6930 - val_categorical_accuracy: 0.6141\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 69s 3s/step - loss: 1.7564 - categorical_accuracy: 0.5590 - val_loss: 1.6936 - val_categorical_accuracy: 0.6176\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 67s 3s/step - loss: 1.7314 - categorical_accuracy: 0.5527 - val_loss: 1.6655 - val_categorical_accuracy: 0.6355\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 69s 3s/step - loss: 1.7050 - categorical_accuracy: 0.5566 - val_loss: 1.6390 - val_categorical_accuracy: 0.6273\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 67s 3s/step - loss: 1.6994 - categorical_accuracy: 0.5656 - val_loss: 1.6099 - val_categorical_accuracy: 0.6500\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 70s 4s/step - loss: 1.6401 - categorical_accuracy: 0.5930 - val_loss: 1.5924 - val_categorical_accuracy: 0.6410\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 68s 3s/step - loss: 1.6136 - categorical_accuracy: 0.5793 - val_loss: 1.6456 - val_categorical_accuracy: 0.6311\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 68s 3s/step - loss: 1.5633 - categorical_accuracy: 0.6031 - val_loss: 1.6390 - val_categorical_accuracy: 0.6355\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 69s 3s/step - loss: 1.5315 - categorical_accuracy: 0.6105 - val_loss: 1.6349 - val_categorical_accuracy: 0.6414\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 68s 3s/step - loss: 1.5311 - categorical_accuracy: 0.6207 - val_loss: 1.6295 - val_categorical_accuracy: 0.6551\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 67s 3s/step - loss: 1.5002 - categorical_accuracy: 0.6109 - val_loss: 1.5508 - val_categorical_accuracy: 0.6555\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 66s 3s/step - loss: 1.4739 - categorical_accuracy: 0.6285 - val_loss: 1.5020 - val_categorical_accuracy: 0.6738\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 67s 3s/step - loss: 1.4394 - categorical_accuracy: 0.6359 - val_loss: 1.5079 - val_categorical_accuracy: 0.6746\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 65s 3s/step - loss: 1.4126 - categorical_accuracy: 0.6574 - val_loss: 1.4770 - val_categorical_accuracy: 0.6749\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 66s 3s/step - loss: 1.4346 - categorical_accuracy: 0.6297 - val_loss: 1.4737 - val_categorical_accuracy: 0.6914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgIZq3YwgLw3"
      },
      "source": [
        "model_fine.evaluate_generator(val_data_gen)\n",
        "\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(40)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM_C_XDjCXwZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "8e6ae8d3-dbf9-4463-ffe8-76e0afddc642"
      },
      "source": [
        "train_data_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'100B': 0,\n",
              " '100F': 1,\n",
              " '10B': 2,\n",
              " '10F': 3,\n",
              " '200B': 4,\n",
              " '200F': 5,\n",
              " '20B': 6,\n",
              " '20F': 7,\n",
              " '50B': 8,\n",
              " '50F': 9,\n",
              " '5B': 10,\n",
              " '5F': 11,\n",
              " 'No_curr': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcXH78AucNd-"
      },
      "source": [
        "model=tf.keras.models.load_model(\"/content/drive/My Drive/GHARBcurr.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckF-Kmx7M3eq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ec1a2a5c-b123-4665-e7e4-f412adb02749"
      },
      "source": [
        "import cv2\n",
        "img=cv2.imread(\"/content/drive/My Drive/Mis_predicted1/164_7.jpg\")\n",
        "dim=(350,350)\n",
        "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "img = img / 255\n",
        "#img = np.array(img, dtype=np.float32)\n",
        "#img = np.reshape(img, (-1, image_x, image_y, 1))\n",
        "pred_probab = model.predict(img)[0]\n",
        "pred_probab "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.5789283e-02, 1.9854952e-03, 4.8894208e-04, 1.6032040e-02,\n",
              "       1.9381220e-02, 5.6533422e-03, 1.5688317e-01, 7.5678986e-01,\n",
              "       1.0659717e-02, 4.1324091e-03, 4.8998510e-04, 1.7144473e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtYk2UaMozgD"
      },
      "source": [
        "### prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FkrY8NoTMSZ"
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "y = ['100',  '100', '10',  '10',  '200',  '200',  '20', '20',  '50',  '50',  '5', '5']\n",
        "#import model\n",
        "model=tf.keras.models.load_model(\"/content/drive/My Drive/hanycurr_84.30%.h5\",compile=False)\n",
        "\n",
        "def Curr_Pred(path):\n",
        "    img=cv2.imread(path)\n",
        "    dim=(350,350)\n",
        "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255\n",
        "    #img = np.array(img, dtype=np.float32)\n",
        "    #img = np.reshape(img, (-1, image_x, image_y, 1))\n",
        "    pred_probab = model.predict(img)[0]\n",
        "\n",
        "    if max(pred_probab) < 0.45:\n",
        "        print(\"Please take another picture\")\n",
        "    else:    \n",
        "        pred_class = list(pred_probab).index(max(pred_probab))\n",
        "        return y[list(pred_probab).index(max(pred_probab))]\n",
        "\n",
        "\n",
        "#predection\n",
        "predec = Curr_Pred(\"/content/drive/My Drive/valid/10B/1 (2).jpg\")        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK0Uh9v9yTMM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "10af5dd4-fcef-43c6-b587-eff7b3883d80"
      },
      "source": [
        "Curr_Pred(\"/content/wrong_predectionXXyy213_3.jpg\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZn9qO-dDmGN"
      },
      "source": [
        "{'100B': 0,\n",
        " '100F': 1,\n",
        " '10B': 2,\n",
        " '10F': 3,\n",
        " '200B': 4,\n",
        " '200F': 5,\n",
        " '20B': 6,\n",
        " '20F': 7,\n",
        " '50B': 8,\n",
        " '50F': 9,\n",
        " '5B': 10,\n",
        " '5F': 11,\n",
        " 'No_curr': 12}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxoTbYXgpCOy"
      },
      "source": [
        "# get the accurcy of our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_UI64KCpH5W"
      },
      "source": [
        "in our data, we considered front and back sides of the currency as diffrent classes. but practically, if we give the model back side and it predicted it as front, that woildn't be a problem.\n",
        "\n",
        "so we need a script to get the practical accurcy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gy9ujRs_gpR"
      },
      "source": [
        "import glob\n",
        "import cv2\n",
        "pred_true=0\n",
        "x=['5B','10B','20B','50B','100B','200B','5F','10F','20F','50F','100F','200F']\n",
        "for xx in x:\n",
        "    data_path = os.path.join(\"/content/Curr_data_13/valid/\"+xx,'*g')\n",
        "    files = glob.glob(data_path)\n",
        "    for f1,img in enumerate(files):\n",
        "        pred_class=validate_test(img)\n",
        "        if (xx == '5B' or xx == '5F') and (pred_class  == 10 or pred_class == 11):\n",
        "            pred_true+= 1\n",
        "\n",
        "        elif (xx == '10B' or xx == '10F')  and (pred_class  == 2 or pred_class == 3):\n",
        "            pred_true+= 1\n",
        "\n",
        "        elif (xx == '20B' or xx == '20F')  and (pred_class  == 6 or pred_class == 7):\n",
        "            pred_true+= 1\n",
        "\n",
        "        elif (xx == '100B'  or xx == '100F')and (pred_class  == 0 or pred_class == 1):\n",
        "            pred_true+= 1\n",
        "\n",
        "        elif (xx == '200B'  or xx == '200F')and (pred_class  == 4 or pred_class == 5):\n",
        "            pred_true+= 1\n",
        "        elif (xx == '50B' or xx == '50F')  and (pred_class  == 8 or pred_class == 9):\n",
        "            pred_true+= 1\n",
        "\n",
        "        else:\n",
        "            img=cv2.imread(img)\n",
        "            cv2.imwrite('/content/Mis_predicted3/'+str(f1)+'_'+str(pred_class)+'.jpg', img)\n",
        "\n",
        "        if f1 % 500 ==0:\n",
        "          print(pred_true)            \n",
        "\n",
        "print(pred_true)\n",
        "\n",
        "no_curr=0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4pke-1naRZu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "37fcef0b-4245-408c-b52d-ff0ad7adbaf1"
      },
      "source": [
        "validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(directory=\"/content/drive/My Drive/valid\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5600 images belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmSouhXmaeEJ"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('new_valid.zip', 'w') as zipObj:\n",
        "   # Iterate over all the files in directory\n",
        "   for folderName, subfolders, filenames in os.walk(\"/content/drive/My Drive/valid\"):\n",
        "       for filename in filenames:\n",
        "           #create complete filepath of file in directory\n",
        "           filePath = os.path.join(folderName, filename)\n",
        "           # Add file to zip\n",
        "           zipObj.write(filePath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FOT1OtceMQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "687c00f9-35b8-45f6-e63a-51af66a4660a"
      },
      "source": [
        "data_path = os.path.join(\"/content/Mis_predicted1\",'*g')\n",
        "files = glob.glob(data_path)\n",
        "len(files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyiUy9kXl5A-"
      },
      "source": [
        "##check models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y4hsFb_l7xG"
      },
      "source": [
        "\n",
        "import cv2\n",
        "dim=(224,224)\n",
        "\n",
        "def validate_test(path):\n",
        "    img=cv2.imread(str(path)) #str(path)\n",
        "    dim=(224,224)\n",
        "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255\n",
        "    #img = np.array(img, dtype=np.float32)\n",
        "    #img = np.reshape(img, (-1, image_x, image_y, 1))\n",
        "    pred_probab = model.predict(img)[0]\n",
        "    return pred_probab\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE98YpK6ngrs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "9fabd53c-4e7c-401f-bc35-901b9b03631d"
      },
      "source": [
        "import cv2\n",
        "\n",
        "def validate_test(path):\n",
        "    dim=(400,400)\n",
        "    img=cv2.imread(str(path)) #str(path)\n",
        "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255\n",
        "    #img = np.array(img, dtype=np.float32)\n",
        "    #img = np.reshape(img, (-1, image_x, image_y, 1))\n",
        "    pred_probab = model.predict(img)[0]\n",
        "    return pred_probab\n",
        "pred_false_true=0\n",
        "very_false=0\n",
        "pred_true=0\n",
        "Models= ['/content/drive/My Drive/hanycurr_84.30%.h5']\n",
        "\n",
        "n_pred_true=[]\n",
        "\n",
        "for mod_path in Models:\n",
        "    pred_true=0\n",
        "    pred_false=0\n",
        "    print(mod_path, '\\n')\n",
        "    model=tf.keras.models.load_model(mod_path,compile=False)\n",
        "    \n",
        "    for xx in x:\n",
        "        data_path = os.path.join(\"/content/content/drive/My Drive/valid/\"+xx,'*g')\n",
        "        files = glob.glob(data_path)\n",
        "        for f1,img in enumerate(files):\n",
        "            pred_probab=validate_test(img)\n",
        "            pred_class = list(pred_probab).index(max(pred_probab))\n",
        "\n",
        "            if (xx == '5B' or xx == '5F') and (pred_class  == 10 or pred_class == 11) : #and max(pred_probab) > 0.5 \n",
        "                pred_true+= 1\n",
        "                if max(pred_probab) > 0.5:\n",
        "                    pred_false_true +=1\n",
        "            elif (xx == '10B' or xx == '10F')  and (pred_class  == 2 or pred_class == 3):\n",
        "                pred_true+= 1\n",
        "                if max(pred_probab) > 0.5:\n",
        "                    pred_false_true +=1\n",
        "                \n",
        "\n",
        "            elif (xx == '20B' or xx == '20F')  and (pred_class  == 6 or pred_class == 7):\n",
        "                pred_true+= 1\n",
        "                if max(pred_probab) > 0.5:\n",
        "                    pred_false_true +=1\n",
        "\n",
        "            elif (xx == '100B'  or xx == '100F')and (pred_class  == 0 or pred_class == 1):\n",
        "                pred_true+= 1\n",
        "                if max(pred_probab) > 0.5:\n",
        "                    pred_false_true +=1\n",
        "\n",
        "            elif (xx == '200B'  or xx == '200F')and (pred_class  == 4 or pred_class == 5):\n",
        "                pred_true+= 1\n",
        "                if max(pred_probab) > 0.5:\n",
        "                    pred_false_true +=1\n",
        "\n",
        "            elif (xx == '50B' or xx == '50F')  and (pred_class  == 8 or pred_class == 9):\n",
        "                pred_true+= 1\n",
        "                if max(pred_probab) > 0.5:\n",
        "                    pred_false_true +=1\n",
        "\n",
        "            else:\n",
        "\n",
        "                if max(pred_probab) > 0.5:\n",
        "                    pred_false+=1\n",
        "                    \n",
        "                else:\n",
        "                   very_false+=1\n",
        "                \n",
        "\n",
        "\n",
        "        print(len(files),\"\\t\",pred_true,\"\\t\",pred_false_true,\"\\t\",pred_false,\"\\t\",very_false,)                \n",
        "    n_pred_true.append(pred_true)\n",
        "    print(n_pred_true, pred_false)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/hanycurr_84.30%.h5 \n",
            "\n",
            "444 \t 429 \t 424 \t 11 \t 4\n",
            "431 \t 835 \t 827 \t 30 \t 10\n",
            "335 \t 1126 \t 1111 \t 63 \t 21\n",
            "413 \t 1479 \t 1448 \t 106 \t 38\n",
            "430 \t 1876 \t 1841 \t 136 \t 41\n",
            "511 \t 2363 \t 2319 \t 149 \t 52\n",
            "492 \t 2791 \t 2736 \t 195 \t 70\n",
            "440 \t 3193 \t 3127 \t 217 \t 86\n",
            "372 \t 3524 \t 3441 \t 242 \t 102\n",
            "445 \t 3864 \t 3762 \t 316 \t 133\n",
            "467 \t 4285 \t 4170 \t 339 \t 156\n",
            "526 \t 4752 \t 4625 \t 377 \t 177\n",
            "[4752] 377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU7HCmsood2-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}